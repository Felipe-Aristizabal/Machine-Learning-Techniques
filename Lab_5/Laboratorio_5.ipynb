{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hectormelo/Machine-Learning-Techniques/blob/main/Lab_5/Laboratorio_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src=\"https://raw.githubusercontent.com/hectormelo/Machine-Learning-Techniques/main/Banner.png\" ><br>\n",
        "# Machine Learning Techniques - MISIS4219\n",
        "\n",
        "Primer semestre - 2024"
      ],
      "metadata": {
        "id": "gX68jANH0FwN"
      },
      "id": "gX68jANH0FwN"
    },
    {
      "cell_type": "markdown",
      "id": "quantitative-piano",
      "metadata": {
        "id": "quantitative-piano"
      },
      "source": [
        "# A first look at a neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caroline-sharp",
      "metadata": {
        "id": "caroline-sharp"
      },
      "source": [
        "Problem: The problem we’re trying to solve here is to classify grayscale images of handwritten digits (28 × 28 pixels) into their 10 categories (0 through 9).\n",
        "\n",
        "We’ll use the MNIST dataset, It’s a set of 60,000 training images, plus 10,000 test images, assembled by the National Institute of Standards and Technology (the NIST in MNIST) in the 1980s.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "promotional-occupation",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "promotional-occupation",
        "outputId": "33a40903-3e42-448f-99e7-85d4f4515fd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "#(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "(train_data, train_data_labels), (test_data, test_data_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "female-compilation",
      "metadata": {
        "id": "female-compilation"
      },
      "source": [
        "## Let’s look at the training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "relevant-lesbian",
      "metadata": {
        "id": "relevant-lesbian",
        "outputId": "5928d5b4-e849-4683-e8c6-45b632a96bc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "historical-opening",
      "metadata": {
        "id": "historical-opening",
        "outputId": "184694d1-c176-4ca5-8ab6-445d873a0629"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_data_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "verified-brush",
      "metadata": {
        "id": "verified-brush",
        "outputId": "69fad76e-07c4-4471-d26f-b00ff4ae0203"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6396b6d5-46ff-4a2a-b57c-6cf029a46bf8",
      "metadata": {
        "id": "6396b6d5-46ff-4a2a-b57c-6cf029a46bf8",
        "outputId": "f53ee185-1834-4c98-8ee1-cb121cb91d8d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_data[4], cmap=plt.cm.binary)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e9cbd3c-6054-4736-b691-296ab036b661",
      "metadata": {
        "id": "1e9cbd3c-6054-4736-b691-296ab036b661",
        "outputId": "8ca62647-a7ad-46f6-b255-6c60d99bd818"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_labels[4]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dominican-summary",
      "metadata": {
        "id": "dominican-summary"
      },
      "source": [
        "## And here’s the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "thirty-meeting",
      "metadata": {
        "id": "thirty-meeting",
        "outputId": "e95a3aab-9455-4c12-f77d-84f6130aadf8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "intelligent-avatar",
      "metadata": {
        "id": "intelligent-avatar",
        "outputId": "7d0b1164-2089-405d-9a58-8f1a6b25346c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test_data_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "willing-question",
      "metadata": {
        "id": "willing-question",
        "outputId": "a02e6172-a75d-413f-a477-f2fbf56525e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "616fa162-0158-448e-9047-c1f39b43acd5",
      "metadata": {
        "id": "616fa162-0158-448e-9047-c1f39b43acd5"
      },
      "source": [
        "## Validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "804aa42e-3b2e-4f60-b414-0799c536cb96",
      "metadata": {
        "id": "804aa42e-3b2e-4f60-b414-0799c536cb96",
        "outputId": "d6397f40-a207-47cf-9be8-121b47366d67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation:  (10000, 28, 28)\n",
            "Training:  (50000, 28, 28)\n",
            "Testing:  (50000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "# Validación\n",
        "val_images = train_data[:10000,:]\n",
        "val_labels = train_data_labels[:10000]\n",
        "print(\"Validation: \", val_images.shape)\n",
        "\n",
        "#Training\n",
        "train_images = train_data[10000:,:]\n",
        "train_labels = train_data_labels[10000:]\n",
        "print(\"Training: \", train_images.shape)\n",
        "\n",
        "#Testing\n",
        "test_images = test_data\n",
        "test_labels = test_data_labels\n",
        "print(\"Testing: \", train_images.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "altered-return",
      "metadata": {
        "id": "altered-return"
      },
      "source": [
        "## The network architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sudden-radiation",
      "metadata": {
        "id": "sudden-radiation"
      },
      "source": [
        "#### Layers extract representations out of the data fed into them — hopefully\n",
        "#### Most of deep learning consists of chaining together simple layers that will implement a form of progressive data distillation\n",
        "#### A deep-learning model is like a sieve for data processing, made of a succession of increasingly refined data filters — the layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "certified-yield",
      "metadata": {
        "id": "certified-yield"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "model = models.Sequential([\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Here, our model consists of a sequence of two Dense layers, which are densely connected (also\n",
        "# called fully connected) neural layers. The second (and last) layer is a 10-way softmax\n",
        "# classification layer, which means it will return an array of 10 probability scores (summing to 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "incorporate-cursor",
      "metadata": {
        "id": "incorporate-cursor"
      },
      "source": [
        "To make the model ready for training, we need to pick three more things, as part of the compilation step:\n",
        "* An optimizer — The mechanism through which the model will update itself based on the training data it sees, so as to improve its performance.\n",
        "* A loss function — How the model will be able to measure its performance on the training data, and thus how it will be able to steer itself in the right direction.\n",
        "* Metrics to monitor during training and testing — Here, we’ll only care about accuracy (the fraction of the images that were correctly classified)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cooked-antarctica",
      "metadata": {
        "id": "cooked-antarctica"
      },
      "source": [
        "# The compilation step"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ada4f7c-5219-47e7-b25d-57e796095966",
      "metadata": {
        "id": "2ada4f7c-5219-47e7-b25d-57e796095966"
      },
      "source": [
        "The compile() method configures the training process\n",
        "\n",
        "<code>model.compile(optimizer='rmsprop',\n",
        "loss='mean_squared_error',\n",
        "metrics=['accuracy'])</code>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5916b46c-1eec-41f9-9832-71a048cc9af4",
      "metadata": {
        "id": "5916b46c-1eec-41f9-9832-71a048cc9af4"
      },
      "source": [
        "![compiler.png](https://raw.githubusercontent.com/hectormelo/Machine-Learning-Techniques/63d050457c26f88265bbd9c74323a3d5509dbdca/Lab_5/images/compiler.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cellular-wright",
      "metadata": {
        "id": "cellular-wright"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "loss='sparse_categorical_crossentropy',\n",
        "metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "julian-space",
      "metadata": {
        "id": "julian-space"
      },
      "source": [
        "### Normalization and flattened - Why we need normalization?\n",
        "\n",
        "Previously, our training images, for instance, were stored in an array of shape (60000, 28, 28) of type uint8 with values in the [0, 255] interval. We transform it into a float32 array of shape (60000, 28 * 28) with values between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "numeric-singapore",
      "metadata": {
        "id": "numeric-singapore"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape((50000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "val_images = val_images.reshape((10000, 28 * 28))\n",
        "val_images = val_images.astype('float32') / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "least-chinese",
      "metadata": {
        "id": "least-chinese",
        "outputId": "ec852218-dae6-46c1-83c8-9680b0d706d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 784)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "further-sauce",
      "metadata": {
        "id": "further-sauce"
      },
      "source": [
        "#### We’re now ready to train the model, which in Keras is done via a call to the model’s fit method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "infectious-property",
      "metadata": {
        "id": "infectious-property",
        "outputId": "3e706223-bea8-4285-b1d8-b1f45ed42643"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 9.4115e-05 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9788\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 2.1443e-04 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9828\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.1277e-04 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 0.9823\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 4.7237e-05 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9826\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.1889e-04 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9817\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.2775e-05 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9822\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 8.8031e-05 - accuracy: 1.0000 - val_loss: 0.1513 - val_accuracy: 0.9814\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.3725e-05 - accuracy: 1.0000 - val_loss: 0.1458 - val_accuracy: 0.9831\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 4.0421e-06 - accuracy: 1.0000 - val_loss: 0.1556 - val_accuracy: 0.9814\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 8.7551e-07 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9819\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 2.0905e-06 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9821\n",
            "Epoch 12/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 6.2306e-07 - accuracy: 1.0000 - val_loss: 0.1561 - val_accuracy: 0.9824\n",
            "Epoch 13/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 4.4807e-07 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9825\n",
            "Epoch 14/20\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.9284e-07 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9825\n",
            "Epoch 15/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.2525e-08 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9827\n",
            "Epoch 16/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.6016e-08 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 0.9818\n",
            "Epoch 17/20\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 2.1658e-08 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9821\n",
            "Epoch 18/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.9288e-08 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9821\n",
            "Epoch 19/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.7710e-08 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9824\n",
            "Epoch 20/20\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.6532e-08 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.9823\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_images, train_labels, epochs=20, batch_size=128 , validation_data=(val_images, val_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fluid-germany",
      "metadata": {
        "id": "fluid-germany"
      },
      "source": [
        "#### Two quantities are displayed during training:\n",
        "* the loss of the model over the training data}\n",
        "* the accuracy of the model over the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0021df2e-f335-4cee-9e3d-a717cc40573c",
      "metadata": {
        "id": "0021df2e-f335-4cee-9e3d-a717cc40573c",
        "outputId": "c376cccd-580c-4642-f42f-ad1d4d5ef348"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Plotting the training and validation loss:\n",
        "import matplotlib.pyplot as plt\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4563187b-a321-41a7-accc-57b2f022ad84",
      "metadata": {
        "id": "4563187b-a321-41a7-accc-57b2f022ad84",
        "outputId": "3f82bb4c-d582-44c4-b29e-2efc62bc4ce4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAuuUlEQVR4nO3deXwV5fn38c/FLoIgi4hEBStKsWwhooILrsWlIqhVpCra4o7V34OKtSo/lZ/V2tYH17ovVdHan2hVRAUpPi7FKIsgoEBRg6jIjsiS5Hr+uCfhJJwkZ5Kcc4L5vl+veWWWe2aumTOZ69z3zJkxd0dERCRVDbIdgIiI7FiUOEREJBYlDhERiUWJQ0REYlHiEBGRWJQ4REQkFiUOqTEzm2Rm59Z22Wwys6Vmdkwalutmtm/Uf7+ZXZ9K2WqsZ7iZvV7dOEUqY/odR/1kZhsSBpsDm4GiaPhCd38q81HVHWa2FPiNu79Zy8t1oKu7L6qtsmbWGfgP0NjdC2slUJFKNMp2AJId7t6ipL+yk6SZNdLJSOoKHY91g5qqpAwzG2hmBWZ2jZl9DTxqZrua2ctmtsLMVkf9OQnzTDOz30T9I8zs/5nZHVHZ/5jZ8dUs28XMppvZejN708zuMbO/VRB3KjHebGbvRMt73czaJUw/28w+N7OVZnZdJfvnIDP72swaJowbYmZzov5+Zvaema0xs+VmdreZNalgWY+Z2S0Jw1dF83xlZueXK3uimc00s3Vm9qWZjU2YPD36u8bMNpjZISX7NmH+/mb2gZmtjf72T3XfxNzPbczs0WgbVpvZxIRpg81sVrQNi81sUDS+TLOgmY0t+ZzNrHPUZPdrM/sCmBqN/3v0OayNjpEDEubfycz+FH2ea6NjbCcze8XMRpXbnjlmNiTZtkrFlDgkmd2BNsDewAWE4+TRaHgv4Afg7krmPwhYCLQDbgceNjOrRtmngRlAW2AscHYl60wlxrOA84DdgCbAaAAz6w7cFy1/j2h9OSTh7v8GvgeOKrfcp6P+IuDKaHsOAY4GLqkkbqIYBkXxHAt0BcpfX/keOAdoDZwIXGxmp0TTDo/+tnb3Fu7+XrlltwFeAcZH2/Zn4BUza1tuG7bbN0lUtZ+fJDR9HhAt6y9RDP2AJ4Crom04HFhawTqSOQL4KfDzaHgSYT/tBnwEJDat3gH0BfoTjuOrgWLgceBXJYXMrBfQibBvJA53V1fPO8I/8DFR/0BgC9CskvK9gdUJw9MITV0AI4BFCdOaAw7sHqcs4aRUCDRPmP434G8pblOyGH+fMHwJ8FrUfwMwIWHaztE+OKaCZd8CPBL1tySc1PeuoOwVwAsJww7sG/U/BtwS9T8C/CGh3H6JZZMs907gL1F/56hso4TpI4D/F/WfDcwoN/97wIiq9k2c/Qx0JJygd01S7q8l8VZ2/EXDY0s+54Rt26eSGFpHZVoREtsPQK8k5ZoBqwnXjSAkmHvT8T/1Y+9U45BkVrj7ppIBM2tuZn+Nqv7rCE0jrROba8r5uqTH3TdGvS1ilt0DWJUwDuDLigJOMcavE/o3JsS0R+Ky3f17YGVF6yLULoaaWVNgKPCRu38exbFf1HzzdRTH/xBqH1UpEwPwebntO8jM3oqaiNYCF6W43JJlf15u3OeEb9slKto3ZVSxn/ckfGark8y6J7A4xXiTKd03ZtbQzP4QNXetY1vNpV3UNUu2ruiYfhb4lZk1AIYRakgSkxKHJFP+Vrv/A+wPHOTuu7CtaaSi5qfasBxoY2bNE8btWUn5msS4PHHZ0TrbVlTY3T8hnHiPp2wzFYQmrwWEb7W7AL+rTgyEGleip4GXgD3dvRVwf8Jyq7o18itC01KivYBlKcRVXmX7+UvCZ9Y6yXxfAj+pYJnfE2qbJXZPUiZxG88CBhOa81oRaiUlMXwHbKpkXY8DwwlNiBu9XLOepEaJQ1LRklD9XxO1l9+Y7hVG3+DzgbFm1sTMDgF+kaYYnwdOMrNDowvZN1H1/8bTwG8JJ86/l4tjHbDBzLoBF6cYw3PACDPrHiWu8vG3JHyb3xRdLzgrYdoKQhPRPhUs+1VgPzM7y8wamdkZQHfg5RRjKx9H0v3s7ssJ1x7ujS6iNzazksTyMHCemR1tZg3MrFO0fwBmAWdG5fOA01KIYTOhVticUKsriaGY0Oz3ZzPbI6qdHBLVDokSRTHwJ1TbqDYlDknFncBOhG9z7wOvZWi9wwkXmFcSris8SzhhJHMn1YzR3ecBlxKSwXJCO3hBFbM9Q7hgO9Xdv0sYP5pwUl8PPBjFnEoMk6JtmAosiv4mugS4yczWE67JPJcw70ZgHPCOhbu5Di637JXASYTawkrCxeKTysWdqjupfD+fDWwl1Lq+JVzjwd1nEC6+/wVYC/yLbbWg6wk1hNXAf1O2BpfME4Qa3zLgkyiORKOBj4EPgFXAbZQ91z0B9CBcM5Nq0A8AZYdhZs8CC9w97TUe+fEys3OAC9z90GzHsqNSjUPqLDM70Mx+EjVtDCK0a0/McliyA4uaAS8BHsh2LDsyJQ6py3Yn3Cq6gfAbhIvdfWZWI5Idlpn9nHA96Buqbg6TSqipSkREYlGNQ0REYqkXDzls166dd+7cOdthiIjsUD788MPv3L19+fH1InF07tyZ/Pz8bIchIrJDMbPyTxwA1FQlIiIxKXGIiEgsShwiIhKLEoeIiMSixCEiIrGkNXGY2SNm9q2Zza1gupnZeDNbFL3CMTdh2rlm9lnUnZswvq+ZfRzNM76SN8uJiEgapLvG8RgwqJLpxxNe/9iV8IrS+6D0VZc3El4r2g+40cx2jea5DxiZMF9lyxcRkVqW1t9xuPt0M+tcSZHBwBMennvyvpm1NrOOhNeXvuHuqwDM7A1gkJlNA3Zx9/ej8U8ApxDeAVD73nkHvv0WGjYs2zVosP24iroGDaAmlaKiItiypfqdOzRpUv3ObMdd/9atUFhYe8eDyI5o1Chov91v+Gok2z8A7ETZ12UWROMqG1+QZPx2zOwCQi2GvfYq/zK1FI0bB5PSk5Mkg9SaKfXZWWf96BJH2rj7A0SPTs7Ly6vekxzvuQfWrg3f+st3xcXJxycrVxMNGkDTptX7tt64cThpbt1a/W/txcV1b/2NG6e+/oYVvRZdRKor24ljGWXfs5wTjVtGaK5KHD8tGp+TpHx6dOmStkVnVMmJtL6uX0RqVbZvx30JOCe6u+pgYG303uLJwHHRe4t3BY4DJkfT1pnZwdHdVOcAL2YtehGReiitNQ4ze4ZQc2hnZgWEO6UaA7j7/cCrwAmEdyxvJLyTGHdfZWY3E94ZDHBTyYVywtu7HiO893gS6bowLiIiSdWLFznl5eW5no4rIhKPmX3o7nnlx2e7qUpERHYwShwiIhKLEoeIiMSixCEiIrEocYiISCxKHCIiEosSh4iIxKLEISIisShxiIhILEocIiISixKHiIjEosQhIiKxKHGIiEgsShwiIhKLEoeIiMSixCEiIrEocYiISCxKHCIiEosSh4iIxKLEISIisShxiIhILEocIiISixKHiIjEosQhIiKxKHGIiEgsShwiIhKLEoeIiMSixCEiIrEocYiISCxKHCIiEosSh4iIxKLEISIisShxiIhILEocIiISixKHiIjEosQhIiKxKHGIiEgsShwiIhJLWhOHmQ0ys4VmtsjMxiSZvreZTTGzOWY2zcxyEqbdZmZzo+6MhPGPmdl/zGxW1PVO5zaIiEhZaUscZtYQuAc4HugODDOz7uWK3QE84e49gZuAW6N5TwRygd7AQcBoM9slYb6r3L131M1K1zaIiMj20lnj6Acscvcl7r4FmAAMLlemOzA16n8rYXp3YLq7F7r798AcYFAaYxURkRSlM3F0Ar5MGC6IxiWaDQyN+ocALc2sbTR+kJk1N7N2wJHAngnzjYuat/5iZk2TrdzMLjCzfDPLX7FiRW1sj4iIkP2L46OBI8xsJnAEsAwocvfXgVeBd4FngPeAomiea4FuwIFAG+CaZAt29wfcPc/d89q3b5/erRARqUfSmTiWUbaWkBONK+XuX7n7UHfvA1wXjVsT/R0XXcM4FjDg02j8cg82A48SmsRERCRD0pk4PgC6mlkXM2sCnAm8lFjAzNqZWUkM1wKPROMbRk1WmFlPoCfwejTcMfprwCnA3DRug4iIlNMoXQt290IzuwyYDDQEHnH3eWZ2E5Dv7i8BA4FbzcyB6cCl0eyNgbdDbmAd8Ct3L4ymPWVm7Qm1kFnARenaBhER2Z65e7ZjSLu8vDzPz8/PdhgiIjsUM/vQ3fPKj8/2xXEREdnBKHGIiEgsShwiIhKLEoeIiMSixCEiIrEocYiISCxKHCIiEosSh4iIxKLEISIisShxiIhILEocIiISixKHiIjEosQhIiKxKHGIiEgsShwiIhKLEoeIiMSixCEiIrEocYiISCxKHCIiEosSh4iIxKLEISIisShxiIhILEocIiISixKHiIjEosQhIiKxKHGIiEgsVSYOM/uFmSnBiIgIkFqN4wzgMzO73cy6pTsgERGp26pMHO7+K6APsBh4zMzeM7MLzKxl2qMTEZE6J6UmKHdfBzwPTAA6AkOAj8xsVBpjExGROqhRVQXM7GTgPGBf4Amgn7t/a2bNgU+Au9IboojsyLZu3UpBQQGbNm3KdihSgWbNmpGTk0Pjxo1TKl9l4gBOBf7i7tMTR7r7RjP7dTViFJF6pKCggJYtW9K5c2fMLNvhSDnuzsqVKykoKKBLly4pzZNKU9VYYEbJgJntZGadoxVOqUacIlKPbNq0ibZt2ypp1FFmRtu2bWPVCFNJHH8HihOGi6JxIiIpUdKo2+J+PqkkjkbuvqVkIOpvEjMuEZGsWLlyJb1796Z3797svvvudOrUqXR4y5Ytlc6bn5/P5ZdfXuU6+vfvX1vh7hBSucaxwsxOdveXAMxsMPBdesMSEakdbdu2ZdasWQCMHTuWFi1aMHr06NLphYWFNGqU/FSYl5dHXl5elet49913ayXWHUUqNY6LgN+Z2Rdm9iVwDXBhesMSEUmfESNGcNFFF3HQQQdx9dVXM2PGDA455BD69OlD//79WbhwIQDTpk3jpJNOAkLSOf/88xk4cCD77LMP48ePL11eixYtSssPHDiQ0047jW7dujF8+HDcHYBXX32Vbt260bdvXy6//PLS5SZaunQphx12GLm5ueTm5pZJSLfddhs9evSgV69ejBkzBoBFixZxzDHH0KtXL3Jzc1m8eHF6dlg5VdY43H0xcLCZtYiGN6S6cDMbBPxfoCHwkLv/odz0vYFHgPbAKuBX7l4QTbsNODEqerO7PxuN70L4PUlb4EPg7MSmNBGpw664AqJv/7Wmd2+4887YsxUUFPDuu+/SsGFD1q1bx9tvv02jRo148803+d3vfsc//vGP7eZZsGABb731FuvXr2f//ffn4osv3u4W1pkzZzJv3jz22GMPBgwYwDvvvENeXh4XXngh06dPp0uXLgwbNixpTLvtthtvvPEGzZo147PPPmPYsGHk5+czadIkXnzxRf7973/TvHlzVq1aBcDw4cMZM2YMQ4YMYdOmTRQXFyddbm1LpakKMzsROABoVnIRxd1vqmKehsA9wLFAAfCBmb3k7p8kFLsDeMLdHzezo4BbgbOj9eUCvYGmwDQzmxT9EPE2wu3BE8zsfuDXwH2pbrCICMDpp59Ow4YNAVi7di3nnnsun332GWbG1q1bk85z4okn0rRpU5o2bcpuu+3GN998Q05OTpky/fr1Kx3Xu3dvli5dSosWLdhnn31Kb3cdNmwYDzzwwHbL37p1K5dddhmzZs2iYcOGfPrppwC8+eabnHfeeTRv3hyANm3asH79epYtW8aQIUOA8FuMTEnlB4D3A82BI4GHgNNIuD23Ev2ARe6+JFrOBGAw4UeDJboD/xX1vwVMTBg/3d0LgUIzmwMMMrO/A0cBZ0XlHifcLqzEIbIjqEbNIF123nnn0v7rr7+eI488khdeeIGlS5cycODApPM0bdq0tL9hw4YUFhZWq0xF/vKXv9ChQwdmz55NcXFxRpNBHKlc4+jv7ucAq939v4FDgP1SmK8T8GXCcEE0LtFsYGjUPwRoaWZto/GDzKy5mbUjJK09Cc1Ta6KEUtEyAYiep5VvZvkrVqxIIVwRqa/Wrl1Lp07hVPLYY4/V+vL3339/lixZwtKlSwF49tlnK4yjY8eONGjQgCeffJKioiIAjj32WB599FE2btwIwKpVq2jZsiU5OTlMnDgRgM2bN5dOT7dUEkfJr0I2mtkewFbC86pqw2jgCDObCRwBLAOK3P114FXgXeAZ4D3C70dS5u4PuHueu+e1b9++lsIVkR+jq6++mmuvvZY+ffrEqiGkaqedduLee+9l0KBB9O3bl5YtW9KqVavtyl1yySU8/vjj9OrViwULFpTWigYNGsTJJ59MXl4evXv35o477gDgySefZPz48fTs2ZP+/fvz9ddf13rsyVjJFf8KC5hdT3ge1dGEaxYOPOjuN1Qx3yHAWHf/eTR8LYC731pB+RbAAnfPSTLtaeBvwCRgBbC7uxeWX0dF8vLyPD8/v9LtFJH0mD9/Pj/96U+zHUbWbdiwgRYtWuDuXHrppXTt2pUrr7wy22GVSvY5mdmH7r7d/ciV1jiiFzhNcfc17v4PYG+gW1VJI/IB0NXMuphZE+BM4KVyy2+X8JKoawl3WGFmDaMmK8ysJ9ATeN1DlnuLcJ0F4FzgxRRiERHJqgcffJDevXtzwAEHsHbtWi68cMf9VUOlF8fdvdjM7iG8jwN33wxsTmXBUY3gMmAy4XbcR9x9npndBORHPygcCNxqZg5MBy6NZm8MvB3dwbWOcJtuSf3xGmCCmd0CzAQeTnVjRUSy5corr6xTNYyaSOV23Clmdirwv15Vu1Y57v4q4VpF4rgbEvqfJ7zno/x8mwh3ViVb5hLCHVsiIpIFqVwcv5DwUMPNZrbOzNab2bo0xyUiInVUKr8c1ytiRUSkVCo/ADw82fjyL3YSEZH6IZWmqqsSuuuBfxJ+rS0iUucdeeSRTJ48ucy4O++8k4svvrjCeQYOHEjJLfwnnHACa9as2a7M2LFjS39PUZGJEyfyySfbHpZxww038Oabb8aIvm6qMnG4+y8SumOBnwGr0x+aiEjNDRs2jAkTJpQZN2HChAofNFjeq6++SuvWrau17vKJ46abbuKYY46p1rLqklRqHOUVAPo1j4jsEE477TReeeWV0pc2LV26lK+++orDDjuMiy++mLy8PA444ABuvPHGpPN37tyZ774LryAaN24c++23H4ceemjpo9ch/EbjwAMPpFevXpx66qls3LiRd999l5deeomrrrqK3r17s3jxYkaMGMHzz4cbSadMmUKfPn3o0aMH559/Pps3by5d34033khubi49evRgwYIF28WU7cevp3KN4y7Cr8UhJJrewEc1WquI1EvZeKp6mzZt6NevH5MmTWLw4MFMmDCBX/7yl5gZ48aNo02bNhQVFXH00UczZ84cevbsmXQ5H374IRMmTGDWrFkUFhaSm5tL3759ARg6dCgjR44E4Pe//z0PP/wwo0aN4uSTT+akk07itNNOK7OsTZs2MWLECKZMmcJ+++3HOeecw3333ccVV1wBQLt27fjoo4+49957ueOOO3jooYfKzJ/tx6+nUuPIJ7z34kPCM6Oucfdf1WitIiIZlNhcldhM9dxzz5Gbm0ufPn2YN29emWal8t5++22GDBlC8+bN2WWXXTj55JNLp82dO5fDDjuMHj168NRTTzFv3rxK41m4cCFdunRhv/3C82LPPfdcpk/fdr/R0KHh2a99+/YtfTBioq1btzJy5Eh69OjB6aefXhp3qo9fL5leXan8APB5YJO7F0Hp40Cau3tmHsMoIj8a2Xqq+uDBg7nyyiv56KOP2LhxI3379uU///kPd9xxBx988AG77rorI0aMYNOmTVUvLIkRI0YwceJEevXqxWOPPca0adNqFG/Jo9kreix7th+/nkqNYwqwU8LwTsCOf1uAiNQbLVq04Mgjj+T8888vrW2sW7eOnXfemVatWvHNN98wadKkSpdx+OGHM3HiRH744QfWr1/PP//5z9Jp69evp2PHjmzdupWnnnqqdHzLli1Zv379dsvaf//9Wbp0KYsWLQLCU26POOKIlLcn249fTyVxNEt8XWzUX7N6johIhg0bNozZs2eXJo5evXrRp08funXrxllnncWAAQMqnT83N5czzjiDXr16cfzxx3PggQeWTrv55ps56KCDGDBgAN26dSsdf+aZZ/LHP/6RPn36lLkg3axZMx599FFOP/10evToQYMGDbjoootS3pZsP349lceqvwOMcvePouG+wN3ufkiN1pxBeqy6SPboseo7hjiPVU/lGscVwN/N7CvAgN2BM2ohThER2QGl8qyqD8ysG7B/NGqhuyd/k7uIiPzoVXmNw8wuBXZ297nuPhdoYWaXpD80ERGpi1K5OD7S3deUDLj7amBk2iISkR+dmK/ykQyL+/mkkjgaWvQqPgi/4wCaxIxLROqpZs2asXLlSiWPOsrdWblyZazfgqRycfw14Fkz+2s0fCFQ+Q3PIiKRnJwcCgoKWLFiRbZDkQo0a9aMnJyclMunkjiuAS4ASm4ynkO4s0pEpEqNGzemS5cu2Q5DalEqj1UvBv4NLCW86/soYH56wxIRkbqqwhqHme0HDIu674BnAdz9yMyEJiIidVFlTVULgLeBk9x9EYCZXZmRqEREpM6qrKlqKLAceMvMHjSzowm/HBcRkXqswsTh7hPd/UygG/AW4dEju5nZfWZ2XIbiExGROiaVi+Pfu/vT7v4LIAeYSbjTSkRE6qFY7xx399Xu/oC7H52ugEREpG6LlThERESUOEREJBYlDhERiUWJQ0REYlHiEBGRWJQ4REQkFiUOERGJRYlDRERiUeIQEZFYlDhERCQWJQ4REYlFiUNERGJJa+Iws0FmttDMFpnZmCTT9zazKWY2x8ymmVlOwrTbzWyemc03s/FmZtH4adEyZ0XdbuncBhERKStticPMGgL3AMcD3YFhZta9XLE7gCfcvSdwE3BrNG9/YADQE/gZcCBwRMJ8w929d9R9m65tEBGR7aWzxtEPWOTuS9x9CzABGFyuTHdgatT/VsJ0B5oBTYCmQGPgmzTGKiIiKUpn4ugEfJkwXBCNSzSb8IpagCFASzNr6+7vERLJ8qib7O7zE+Z7NGqmur6kCas8M7vAzPLNLH/FihW1sT0iIkL2L46PBo4ws5mEpqhlQJGZ7Qv8lPDGwU7AUWZ2WDTPcHfvARwWdWcnW3D0wqk8d89r3759urdDRKTeSGfiWAbsmTCcE40r5e5fuftQd+8DXBeNW0Oofbzv7hvcfQMwCTgkmr4s+rseeJrQJCYiIhmSzsTxAdDVzLqYWRPgTOClxAJm1s7MSmK4Fngk6v+CUBNpZGaNCbWR+dFwu2jexsBJwNw0boOIiJSTtsTh7oXAZcBkYD7wnLvPM7ObzOzkqNhAYKGZfQp0AMZF458HFgMfE66DzHb3fxIulE82sznALEIN5sF0bYOIiGzP3D3bMaRdXl6e5+fnZzsMEZEdipl96O555cdn++K4iIjsYJQ4REQkFiUOERGJRYlDRERiUeIQEZFYlDhERCQWJQ4REYlFiUNERGJR4hARkViUOEREJBYlDhERiUWJQ36U3GHMGDj8cPhG744UqVWNsh2ASG1zh8svh7vvhgYN4MgjYepU2H33bEcm8uOgGkcabdkC33+f7Sjql+JiuPTSkDRGjw4J44svQvJYvjzb0Yn8OChxpNGwYdC6dThp/fGP8Mkn4duwpEdxMVx8Mdx3H1x9Ndx+OxxxBEyaBF9+CQMHwrJlVS5G6oCiIigogM8/z3Ykkozex5Emn30G++0XTlarVsGcOWF8585wwgmhO/JIaN48PevfsgUWLoQWLaBLl/Ssoy4pLoYLL4SHHoJrr4Vx48Bs2/R33oFBg0Jz1VtvQU5O9mKt79xh7dpQE/zii5DUS/pLhgsKQvIAGDoUbr4ZunfPbtz1UUXv41DiSJMrroB77w3/CLvvHv4ZXn01dG++CRs3QrNmIXmceGJIJNU5wRcXh29lc+fCxx+Hbu5cWLAACgvDyfPss2Hs2B9vAikuhpEj4ZFH4Pe/h5tuKps0Srz7bkgeu+0Wkseee2Y+1rqquBjWrw8n9MRu48aaLfeHH8omhpL+9evLlmvcOCTzvfYq2xUUwJ13hibfX/3qx30c10VKHBlMHOvXQ6dOMHgwPPnk9tM3bYLp0+GVV0K3eHEY/9OfhgRy4okwYAA0aVJ2vhUrtk8Qc+fChg3bynTuDD/7GfToEf7OmgV33RW+vY0cGU6sHTuma8szr6gIfv1rePxxuPHG0CVLGiXefx9+/nNo1y4kj732ylysmeIemuQ+/hiWLNk+GZTv1q0Lx2w6TwW77RYSdWJSSBzu0CHcyJDMd9/BH/4QrlsVF8MFF8B11/24juPyvv02fH6ffw477wytWm3f7bxz5cd6bVDiyGDiuPtuGDUKZsyAAw+suvynn4aayCuvwL/+BVu3QsuWcNxx4VvYvHnhIEq8rbRt25AcSrqf/QwOOAB22WX75X/1FdxyCzz4YPhmN2pUuAbQtm3tbXM2FBXBeeeF5Dx2bEgaqZgxI+zbXXcNyaNz53RGmV6rV2/7MpH4d82asuWaNt3+xLPLLslPSInTanpyato0fInaaacabSYQah+33AIPPxyO48svD8dxmzY1X3a2bNiw7f878UvhihVVz9ugQeWfYUl3/vnQvn314lPiyFDiKC4ONYc2beC99+LPv349TJkSksirr4YTwwEHbEsOJYmiQ4f4/9BLloQT7N/+FhLT6NGhSa1ly/hxVmX58nBRessWGD689tdRWAgjRsBTT4X279//Pt78+flw7LHhH2/atLrf/LFpE8yfX/bk8vHHZS/2t2pV9hjp0QO6dg0JsmnT7MVe2xYtCsfx00+H4+qqq8Jx3KJFtiOr2Nat4Qti+c/vP//ZVqZ5823/6yXdPvuE5r6KaopV1SYLC8N6u3atXtxKHBlKHK+9BscfHw7qYcNqtiz30FVUha+uuXPhhhvghRdCk83vfhfuRmrWrPrLLCoK3+RLak4zZ26b1rp1uEX28stDk0VNFRaG6zYTJsD//E+4GF4dH30ExxwTTjjTpoV/0mxJvGCceE1g0aLweX322baLxU2ahC8n5b9M5OSkv+miLvn4Y7j+enjxxfCN+rrrwg0SNTmO3cN+Tzyx1+QUuWFDuJtywYLwJQqgYcNw40z5z69Ll9r9X3cPSadp07DO6lDiyFDiOOGEcNL8/PPtr1HUNTNmhG/qb7wRTjo33BC+xTdunNr8q1bB5MkhUbz2GqxcGQ78/v23XfDftCncFvu//xsO4PPOCzWd6p6kt24NF0mfey60e19zTfWWU2LmzJA8mjcPzVb77luz5VVky5ZQOyh/91DicPkLxo0awd57l71mVVKLSPUzqg/efz8kjalTw3WTG2+Ec88N+68yK1eWvV5Y8jfxc9htt6qXU5nEJF/yGXbrVrPklkkVJQ7c/Uff9e3b1zNh4cJQR/jv/87I6mrN1KnuBx8cYu/a1f2ZZ9yLirYvV1zsPmuW+7hx7gMGuDdoEOZp18797LPDfCtXJl/HggXuv/mNe5MmYb4zz3SfOTNenFu2uJ92WljnH/8YezMrNGuWe9u27p06uX/6ac2Xt2mT++TJ7r/9rftBB7l37OhuVlJ/3Na1a+eem+t+yinuo0aFbXr2Wff33nNftsy9sLDmsdQnb77p3q/ftuN4woRwHH//vXt+vvujj7r/13+5H3ts+EwSP4tdd3U//HD3Sy91v/9+93fecV+zJttblH1Avic5p2b9pJ6JLlOJY9Qo98aN3b/+OiOrq1XFxe4vveTeo0c4Knr2dP/nP93XrXN/4QX3kSPDibXkHy031/36693ffz/eCW7ZMverr3Zv2TIs57jj3KdMCeuvzObN7kOHhnn+/OcabWpSs2eHE3nHjiHJxfXFF+5//av7ySe777xziLNZM/eBA93PO8/9xhvdH37Y/Y03wvK//77WN0E8HEcTJ7ofcMC25JyYtJs1C8fuueeGRP3aa+GYrOr4q6+UONJs7Vr3Fi3CN+8dWVGR+9NPu++7bzg6SmoVLVu6n3pqOPl99VXN17N6tfutt7p36BCWf+CB7s8/nzwJbd7sPnhwKHfnnTVfd0U+/ti9fXv33Xd3nz+/8rJbt7pPn+4+ZkxIsiUnpr33dr/kEveXX1ZyyKbCQvcnn3QfPjwk7b//PSRs1eLiUeJIs/Hjw96cMSPtq8qILVvcH3oonBinTg0n73T44YfwTb0kUXXt6v7AA6G5xz38/cUvwrS77kpPDInmzQvJrEOH0J/o22/dn3jC/Ywz3Fu3DjE1ahRqFbffHsrrm6v8mFSUOHRxvBYUF4cLXu3ahV8nS3xFReEC+m23wYcfhh93XXEFvP02vPwy3HMPXHJJZmKZPx+OOip8rg88ALNnh7vFZswI9YoOHcKdcyeeGG7pbdUqM3GJZJruqkpj4pg0KdxB9MwzcOaZaVtNveAe7o75wx/Co1kA7r8/3GaZSQsXbnuirln4IWfJnWK5ubV/i7RIXaTEkcbEcfzx4SGGS5fqNsnaNHNm+AHkUUdlZ/3LloVbPQ87rHZ+fyKyo6kocehFTjW0cGH4DcPNNytp1LY+fbK7/k6d4NRTsxuDSF2kCncN3X13+JHPBRdkOxIRkcxQ4qiBtWvhscfCo0XUlCEi9YUSRw089lh4Fs2oUdmOREQkc5Q4qqm4OLznYsAA6Ns329GIiGSOEkc1TZoUXsB0+eXZjkREJLOUOKpp/Phw182QIdmOREQks5Q4qmH+fHj99fAOC92CKyL1jRJHNdx9d3i3hG7BFZH6KK2Jw8wGmdlCM1tkZmOSTN/bzKaY2Rwzm2ZmOQnTbjezeWY238zGm4V3m5lZXzP7OFpm6fhMWbMGHn883IJb3ff4iojsyNKWOMysIXAPcDzQHRhmZt3LFbsDeMLdewI3AbdG8/YHBgA9gZ8BBwJHRPPcB4wEukbdoHRtQzKPPgrff69bcEWk/kpnjaMfsMjdl7j7FmACMLhcme7A1Kj/rYTpDjQDmgBNgcbAN2bWEdjF3d+PHvn7BHBKGrehjKKi0Ex16KHhQXciIvVROhNHJ+DLhOGCaFyi2cDQqH8I0NLM2rr7e4REsjzqJrv7/Gj+giqWCYCZXWBm+WaWv2LFihpvDIRHay9ZoltwRaR+y/bF8dHAEWY2k9AUtQwoMrN9gZ8COYTEcJSZHRZnwe7+gLvnuXte+1q6GDF+POTkwCmn1MriRER2SOlMHMuAPROGc6Jxpdz9K3cf6u59gOuicWsItY/33X2Du28AJgGHRPPnVLbMdPnkk/B+iEsu0S24IlK/pTNxfAB0NbMuZtYEOBN4KbGAmbUzs5IYrgUeifq/INREGplZY0JtZL67LwfWmdnB0d1U5wAvpnEbSt11V7gFd+TITKxNRKTuSlvicPdC4DJgMjAfeM7d55nZTWZ2clRsILDQzD4FOgDjovHPA4uBjwnXQWa7+z+jaZcADwGLojKT0rUNJVavhieegOHDw+thRUTqM70BMAV/+hOMHh3eSNe7d+3FJSJSl1X0BsBsXxyv80puwT38cCUNERFQ4qjSyy+Hd4nrFlwRkUCJowrjx8Oee8Lg8j9dFBGpp5Q4KjF3LkydGm7BbdQo29GIiNQNShyVuOsuaNYMfvObbEciIlJ3KHFU4ic/gd/+VrfgiogkUgNMJa6+OtsRiIjUPapxiIhILEocIiISixKHiIjEosQhIiKxKHGIiEgsShwiIhKLEoeIiMSixCEiIrHUi/dxmNkK4PNsx1GBdsB32Q6iEoqvZhRfzSi+mqlpfHu7e/vyI+tF4qjLzCw/2YtS6grFVzOKr2YUX82kKz41VYmISCxKHCIiEosSR/Y9kO0AqqD4akbx1Yziq5m0xKdrHCIiEotqHCIiEosSh4iIxKLEkQFmtqeZvWVmn5jZPDP7bZIyA81srZnNirobMhzjUjP7OFp3fpLpZmbjzWyRmc0xs9wMxrZ/wn6ZZWbrzOyKcmUyuv/M7BEz+9bM5iaMa2Nmb5jZZ9HfXSuY99yozGdmdm4G4/ujmS2IPr8XzKx1BfNWeiykMb6xZrYs4TM8oYJ5B5nZwuhYHJPB+J5NiG2pmc2qYN5M7L+k55SMHYPuri7NHdARyI36WwKfAt3LlRkIvJzFGJcC7SqZfgIwCTDgYODfWYqzIfA14YdJWdt/wOFALjA3YdztwJiofwxwW5L52gBLor+7Rv27Zii+44BGUf9tyeJL5VhIY3xjgdEpfP6LgX2AJsDs8v9L6Yqv3PQ/ATdkcf8lPadk6hhUjSMD3H25u38U9a8H5gOdshtVbIOBJzx4H2htZh2zEMfRwGJ3z+qTANx9OrCq3OjBwONR/+PAKUlm/TnwhruvcvfVwBvAoEzE5+6vu3thNPg+kFPb601VBfsvFf2ARe6+xN23ABMI+71WVRafmRnwS+CZ2l5vqio5p2TkGFTiyDAz6wz0Af6dZPIhZjbbzCaZ2QGZjQwHXjezD83sgiTTOwFfJgwXkJ3kdyYV/8Nmc/8BdHD35VH/10CHJGXqyn48n1CDTKaqYyGdLoua0h6poJmlLuy/w4Bv3P2zCqZndP+VO6dk5BhU4sggM2sB/AO4wt3XlZv8EaH5pRdwFzAxw+Ed6u65wPHApWZ2eIbXXyUzawKcDPw9yeRs778yPLQJ1Ml73c3sOqAQeKqCItk6Fu4DfgL0BpYTmoPqomFUXtvI2P6r7JySzmNQiSNDzKwx4QN+yt3/t/x0d1/n7hui/leBxmbWLlPxufuy6O+3wAuEJoFEy4A9E4ZzonGZdDzwkbt/U35Ctvdf5JuS5rvo77dJymR1P5rZCOAkYHh0YtlOCsdCWrj7N+5e5O7FwIMVrDfb+68RMBR4tqIymdp/FZxTMnIMKnFkQNQm+jAw393/XEGZ3aNymFk/wmezMkPx7WxmLUv6CRdR55Yr9hJwjgUHA2sTqsSZUuE3vWzuvwQvASV3qJwLvJikzGTgODPbNWqKOS4al3ZmNgi4GjjZ3TdWUCaVYyFd8SVeMxtSwXo/ALqaWZeoBnomYb9nyjHAAncvSDYxU/uvknNKZo7BdF75V1d6F8OhhCrjHGBW1J0AXARcFJW5DJhHuEvkfaB/BuPbJ1rv7CiG66LxifEZcA/hjpaPgbwM78OdCYmgVcK4rO0/QgJbDmwltBH/GmgLTAE+A94E2kRl84CHEuY9H1gUdedlML5FhLbtkmPw/qjsHsCrlR0LGYrvyejYmkM4AXYsH180fALhLqLFmYwvGv9YyTGXUDYb+6+ic0pGjkE9ckRERGJRU5WIiMSixCEiIrEocYiISCxKHCIiEosSh4iIxKLEIVJNZlZkZZ/aW2tPajWzzolPZhWpSxplOwCRHdgP7t4720GIZJpqHCK1LHofw+3ROxlmmNm+0fjOZjY1eojfFDPbKxrfwcL7MWZHXf9oUQ3N7MHofQuvm9lOUfnLo/cwzDGzCVnaTKnHlDhEqm+nck1VZyRMW+vuPYC7gTujcXcBj7t7T8IDBsdH48cD//LwgMZcwi+OAboC97j7AcAa4NRo/BigT7Sci9KzaSIV0y/HRarJzDa4e4sk45cCR7n7kuhBdF+7e1sz+47wGI2t0fjl7t7OzFYAOe6+OWEZnQnvTOgaDV8DNHb3W8zsNWAD4QnAEz16uKNIpqjGIZIeXkF/HJsT+ovYdk3yRMJzw3KBD6IntopkjBKHSHqckfD3vaj/XcLTXAGGA29H/VOAiwHMrKGZtapooWbWANjT3d8CrgFaAdvVekTSSd9URKpvJzOblTD8mruX3JK7q5nNIdQahkXjRgGPmtlVwArgvGj8b4EHzOzXhJrFxYQnsybTEPhblFwMGO/ua2ppe0RSomscIrUsusaR5+7fZTsWkXRQU5WIiMSiGoeIiMSiGoeIiMSixCEiIrEocYiISCxKHCIiEosSh4iIxPL/AXFvh3KWhCq8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Plotting the training and validation accuracy:\n",
        "##----------------------------------------------\n",
        "plt.clf()\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "plt.plot(epochs, acc, 'r', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6eca396-ebf8-4805-83f1-2b4230273938",
      "metadata": {
        "id": "f6eca396-ebf8-4805-83f1-2b4230273938"
      },
      "source": [
        "![Overfitting.png](https://raw.githubusercontent.com/hectormelo/Machine-Learning-Techniques/63d050457c26f88265bbd9c74323a3d5509dbdca/Lab_5/images/OVerfitting.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "159a9931-18fa-468d-954d-0e01cb6c0982",
      "metadata": {
        "id": "159a9931-18fa-468d-954d-0e01cb6c0982",
        "outputId": "b95cdd9f-c48a-47cf-83bf-f8058de567f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65fda88f-c230-4d3c-a19c-7ba4a7d7ee74",
      "metadata": {
        "id": "65fda88f-c230-4d3c-a19c-7ba4a7d7ee74",
        "outputId": "0f428d9d-23c5-4103-f863-68f81fa096fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense/kernel:0' shape=(784, 512) dtype=float32, numpy=\n",
              " array([[ 0.05811888,  0.04509299,  0.00270712, ...,  0.03765269,\n",
              "         -0.06040028,  0.05417474],\n",
              "        [ 0.02577528, -0.00878131,  0.05641852, ...,  0.03059413,\n",
              "         -0.02965935, -0.0667793 ],\n",
              "        [ 0.00714118, -0.03349832, -0.00773904, ..., -0.03689748,\n",
              "         -0.06007392,  0.04917642],\n",
              "        ...,\n",
              "        [-0.04498671, -0.00861797,  0.05772537, ..., -0.00535517,\n",
              "         -0.03892407, -0.04380159],\n",
              "        [ 0.0244019 ,  0.04716511,  0.05790272, ..., -0.02817658,\n",
              "          0.02885389,  0.01668351],\n",
              "        [-0.01397143,  0.04874928,  0.05514184, ..., -0.06795844,\n",
              "          0.03288513, -0.05946378]], dtype=float32)>,\n",
              " <tf.Variable 'dense/bias:0' shape=(512,) dtype=float32, numpy=\n",
              " array([-0.06679834,  0.09521975, -0.0792907 , -0.10710454,  0.02362659,\n",
              "         0.00886257,  0.02669915, -0.00122225, -0.0487694 , -0.0772546 ,\n",
              "        -0.07648868,  0.02510928, -0.07121716, -0.065308  , -0.09568981,\n",
              "        -0.04821764, -0.00360608, -0.10712809, -0.08280914, -0.16340284,\n",
              "         0.19835812, -0.03601712, -0.08840576, -0.10632876,  0.11224756,\n",
              "        -0.08044863, -0.10993642, -0.05137854, -0.06346445,  0.01176787,\n",
              "        -0.09125026,  0.03348372, -0.08864728, -0.03852396, -0.02848052,\n",
              "         0.0395786 , -0.02943522, -0.0308557 , -0.00687835, -0.05813954,\n",
              "        -0.06835006, -0.08688633,  0.03962696, -0.00410008,  0.04618091,\n",
              "        -0.02831269, -0.03723062,  0.04721272, -0.08181451, -0.01348272,\n",
              "        -0.12388836,  0.02616428, -0.01260943,  0.00041593,  0.10994464,\n",
              "        -0.03355496, -0.09992521, -0.03120157, -0.03705503,  0.02889415,\n",
              "        -0.05632591, -0.18940963, -0.0438714 , -0.01582964, -0.04433763,\n",
              "        -0.00991218, -0.0875285 ,  0.09914427, -0.07039183, -0.11573582,\n",
              "        -0.00975534,  0.02650426,  0.05260198,  0.03496361, -0.01614784,\n",
              "        -0.04252164, -0.0110547 ,  0.00064369,  0.00155601, -0.1404373 ,\n",
              "        -0.07745606, -0.00396079,  0.0022023 , -0.04891   ,  0.06294834,\n",
              "        -0.1042832 ,  0.00953997, -0.10521143, -0.07363409,  0.06658875,\n",
              "        -0.06800348,  0.05700972, -0.07709876, -0.00787035, -0.11998097,\n",
              "        -0.02879738, -0.00787482, -0.14134718, -0.02109602, -0.00703498,\n",
              "         0.01367809,  0.07653124, -0.00180301, -0.0532379 , -0.02010305,\n",
              "        -0.07048519, -0.01840447, -0.0696466 , -0.03203109, -0.13519885,\n",
              "         0.04691163, -0.07231718,  0.0477867 ,  0.00678808, -0.0151601 ,\n",
              "        -0.13140951, -0.06423913,  0.07978616, -0.04785319, -0.14375345,\n",
              "        -0.01867072, -0.107372  , -0.02523298, -0.00162177,  0.01085392,\n",
              "         0.10525365, -0.02330426,  0.00465736, -0.12785375,  0.00445794,\n",
              "        -0.02419727, -0.01382484,  0.00208533, -0.15522882, -0.07625708,\n",
              "        -0.09893436,  0.06045764, -0.13890463, -0.11271002, -0.02948559,\n",
              "         0.06336576, -0.12238882, -0.09507939, -0.02130577, -0.08806058,\n",
              "        -0.1580432 ,  0.04219304,  0.07411528, -0.08139531,  0.03121809,\n",
              "         0.03159219,  0.09263036, -0.09491868, -0.075133  ,  0.00386807,\n",
              "        -0.0476326 , -0.01410368,  0.0532494 , -0.05864939, -0.02053322,\n",
              "        -0.01435475,  0.05949038, -0.076152  , -0.06621239, -0.04002394,\n",
              "         0.02522898, -0.17145854, -0.10891774, -0.04688886, -0.11001432,\n",
              "        -0.10221312, -0.00945833,  0.10239605,  0.01962476,  0.03586675,\n",
              "        -0.09453311, -0.11685607, -0.0680519 ,  0.01814867, -0.100812  ,\n",
              "         0.00453408,  0.06684338, -0.0016071 , -0.08055636,  0.00212486,\n",
              "         0.17834884, -0.01096143, -0.06766468, -0.04604466,  0.02981059,\n",
              "        -0.07661118, -0.06841304,  0.06918386,  0.08326488,  0.01736303,\n",
              "         0.06437176,  0.05432835, -0.03978685, -0.03784245, -0.16312699,\n",
              "        -0.03793191,  0.0010892 , -0.01073895,  0.00836128,  0.00032368,\n",
              "        -0.01295051, -0.08701196, -0.02484299,  0.04179617, -0.03402071,\n",
              "        -0.10461926, -0.03754542, -0.0659623 ,  0.02817143, -0.072797  ,\n",
              "        -0.01410892,  0.04297964, -0.1027436 ,  0.02754765, -0.00431919,\n",
              "         0.0832285 ,  0.00649289,  0.05497509, -0.04513719,  0.02474128,\n",
              "        -0.06502371, -0.09802067, -0.05201307, -0.02553494, -0.00318628,\n",
              "         0.02192239, -0.01847439, -0.04428884, -0.12430824, -0.19720383,\n",
              "         0.06336229, -0.00542574,  0.01342646, -0.01386971,  0.03786468,\n",
              "        -0.03396375, -0.04397825,  0.00534156, -0.06961372, -0.01737317,\n",
              "         0.07617354,  0.07539001,  0.01800305,  0.09978833, -0.11893261,\n",
              "         0.02775661, -0.05697099,  0.02753936, -0.05274921,  0.0100678 ,\n",
              "        -0.12312933, -0.0658424 , -0.04248055, -0.22024085, -0.05428932,\n",
              "        -0.02256614, -0.05697727,  0.05970431, -0.11449196,  0.03095146,\n",
              "        -0.01429174,  0.01093095,  0.00837739, -0.10445061, -0.12567063,\n",
              "        -0.02315844, -0.07178242, -0.00914241, -0.04800907, -0.07134155,\n",
              "        -0.11484704, -0.05613885, -0.0741493 , -0.01967605, -0.10503382,\n",
              "         0.06762838, -0.01937145,  0.01146697, -0.0794316 , -0.0129096 ,\n",
              "        -0.07269298, -0.09106492, -0.09539604, -0.05068741, -0.11604704,\n",
              "        -0.05969074,  0.0461463 , -0.07521098, -0.15263481, -0.09823188,\n",
              "         0.01240079,  0.00574304,  0.15839204,  0.01389036,  0.02065691,\n",
              "        -0.06148902,  0.08453501,  0.01676522,  0.00584782, -0.05879742,\n",
              "         0.11086109,  0.01452746, -0.07572978, -0.00197834, -0.03585682,\n",
              "        -0.1272934 ,  0.02868593,  0.0205313 , -0.13311549, -0.0084168 ,\n",
              "        -0.0273831 ,  0.0816917 , -0.04584162, -0.01021795, -0.07503412,\n",
              "         0.01773918,  0.03850373,  0.01685366, -0.0352373 , -0.0624902 ,\n",
              "        -0.02760069, -0.0857619 , -0.11212339, -0.10274319, -0.06860164,\n",
              "         0.01420623,  0.01742402,  0.02200431, -0.12354679, -0.03541758,\n",
              "        -0.05137118, -0.0755206 ,  0.00850113,  0.07674493, -0.01544972,\n",
              "        -0.07946513, -0.10563546,  0.111108  ,  0.01107393, -0.14820498,\n",
              "        -0.10032738, -0.10921841,  0.02357774,  0.04262063,  0.05551128,\n",
              "         0.01949523, -0.0814383 , -0.0312643 , -0.08156345, -0.1035485 ,\n",
              "         0.07501519,  0.00054714, -0.05115063,  0.03646427, -0.04070776,\n",
              "        -0.02221308, -0.08801475, -0.0229561 , -0.1007694 , -0.02680682,\n",
              "         0.00132479, -0.01252838, -0.01582888,  0.03590181,  0.02572384,\n",
              "        -0.03965906,  0.00457172,  0.00186816,  0.05751122,  0.04192709,\n",
              "         0.01152264, -0.03735426, -0.06278372, -0.03042541,  0.04420706,\n",
              "         0.00967553,  0.02547883, -0.07887726, -0.16879366,  0.06234517,\n",
              "        -0.12253159,  0.01689314,  0.07947481, -0.08679854, -0.00458082,\n",
              "        -0.1017157 , -0.0717174 ,  0.11850514,  0.00792253,  0.02519868,\n",
              "        -0.0240337 , -0.0518813 , -0.04603016, -0.00055647,  0.03578484,\n",
              "        -0.05025967, -0.05891312,  0.00379211, -0.00587195, -0.05761764,\n",
              "        -0.16239011, -0.0070769 , -0.0577972 , -0.07187662, -0.01644097,\n",
              "        -0.00561219, -0.11967629,  0.02650635, -0.01732372,  0.01050838,\n",
              "        -0.06578376,  0.03068112,  0.05127751, -0.11896735,  0.04659095,\n",
              "         0.05990212, -0.03271267,  0.00713418, -0.06131545, -0.04892908,\n",
              "         0.0279438 ,  0.00261599, -0.05982369, -0.01459717, -0.00107393,\n",
              "        -0.08075422, -0.05271455, -0.04033966, -0.06245343, -0.04303095,\n",
              "        -0.14766842, -0.01520856,  0.02956937,  0.05855797, -0.04288605,\n",
              "        -0.08012579,  0.00827405,  0.00317379, -0.10581243, -0.06668779,\n",
              "        -0.03394081, -0.03999273, -0.03550378, -0.0284965 , -0.14068364,\n",
              "         0.06525342, -0.0910015 , -0.01926688, -0.06890488, -0.02791262,\n",
              "        -0.19760223, -0.01610155, -0.15821859, -0.02538791,  0.04131962,\n",
              "         0.09322385, -0.03195944,  0.00914081, -0.14237536, -0.0172174 ,\n",
              "        -0.11363265, -0.00638369, -0.12457363, -0.05019606, -0.06709301,\n",
              "        -0.07093176, -0.00524242, -0.05802675, -0.02228131, -0.03298001,\n",
              "         0.03078304, -0.17619321, -0.04297195, -0.06865742, -0.09752415,\n",
              "        -0.11863194,  0.0444161 , -0.00764649, -0.07021322,  0.01149585,\n",
              "        -0.00391321, -0.14736162,  0.01762518, -0.0257459 , -0.02997219,\n",
              "        -0.10190709, -0.125111  , -0.01633809, -0.08091192, -0.02696992,\n",
              "        -0.08817558,  0.04400773, -0.08532477, -0.09587585, -0.08515274,\n",
              "        -0.10183136, -0.02726044, -0.05849375, -0.13873956, -0.0857005 ,\n",
              "         0.00930452, -0.09803186, -0.05834263, -0.07487848,  0.07268064,\n",
              "        -0.01489785, -0.00577923], dtype=float32)>,\n",
              " <tf.Variable 'dense_1/kernel:0' shape=(512, 10) dtype=float32, numpy=\n",
              " array([[-0.1394552 , -0.26130584, -0.21904343, ..., -0.03271125,\n",
              "         -0.58985114,  0.3675346 ],\n",
              "        [-0.13182534, -0.28433713, -0.86792463, ..., -0.23535551,\n",
              "         -0.15664653,  0.10168739],\n",
              "        [ 0.3084526 , -0.01033102,  0.23840812, ..., -0.3061641 ,\n",
              "          0.00357927, -0.42762288],\n",
              "        ...,\n",
              "        [-0.13590609, -0.69368863, -0.46665058, ..., -0.38988712,\n",
              "         -0.3492067 , -0.17711648],\n",
              "        [ 0.09466881, -0.18678188,  0.0812824 , ..., -0.30149966,\n",
              "          0.04682873,  0.1260336 ],\n",
              "        [-0.37374306,  0.12853545,  0.22554012, ...,  0.07614832,\n",
              "         -0.81275994, -0.4041931 ]], dtype=float32)>,\n",
              " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=\n",
              " array([-0.05649464, -0.11380638, -0.0687172 , -0.03551423,  0.02311302,\n",
              "        -0.03514255, -0.04828766, -0.07096508,  0.03471064, -0.03868952],\n",
              "       dtype=float32)>]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8252d766-2d8d-49cf-a518-258cc27e15af",
      "metadata": {
        "id": "8252d766-2d8d-49cf-a518-258cc27e15af",
        "outputId": "5de882c8-e419-4181-e386-47e24d8c33ed"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, \"digits_classifier.png\", show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "recent-quarter",
      "metadata": {
        "id": "recent-quarter"
      },
      "source": [
        "# Using the model to make predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "divided-hardware",
      "metadata": {
        "id": "divided-hardware",
        "outputId": "b1d84284-7c2f-4c40-85eb-de242dd562a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([1.8369069e-20, 7.0609919e-31, 7.3976148e-19, 1.3016166e-15,\n",
              "       3.2866518e-29, 9.9465213e-21, 2.5660109e-37, 1.0000000e+00,\n",
              "       7.0083507e-21, 5.7638051e-16], dtype=float32)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_digits = test_images[0:10]\n",
        "predictions = model.predict(test_digits)\n",
        "predictions[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hired-potato",
      "metadata": {
        "id": "hired-potato"
      },
      "source": [
        "Each number of index i in that array corresponds to the probability that digit image test_digits[0] belong to class i."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "comparable-tribute",
      "metadata": {
        "id": "comparable-tribute",
        "outputId": "0d549d93-3782-42c5-aa12-df0cddf9a2f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions[0].argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "exciting-campaign",
      "metadata": {
        "id": "exciting-campaign",
        "outputId": "8a6d6c19-98a6-4466-a7ef-d0222f6cf26b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions[0][7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f32e6f63-8a02-4b77-91c3-a112acbe754e",
      "metadata": {
        "id": "f32e6f63-8a02-4b77-91c3-a112acbe754e",
        "outputId": "7851b9ad-d463-49cb-bf79-85bda9620068"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_labels[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sound-tribe",
      "metadata": {
        "id": "sound-tribe"
      },
      "source": [
        "### We can check that the test label agrees:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "creative-georgia",
      "metadata": {
        "id": "creative-georgia",
        "outputId": "fe205bee-7baa-4da3-a076-517b374a9496"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_labels[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dietary-senator",
      "metadata": {
        "id": "dietary-senator"
      },
      "source": [
        "# Evaluating the model on new data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "english-jenny",
      "metadata": {
        "id": "english-jenny",
        "outputId": "293432e0-8c2a-4e1c-836d-0c3976e6a22d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.1340 - accuracy: 0.9812\n",
            "test_acc: 0.9811999797821045\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('test_acc:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "medium-angle",
      "metadata": {
        "id": "medium-angle"
      },
      "source": [
        "# Data representations for neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "neural-listening",
      "metadata": {
        "id": "neural-listening"
      },
      "source": [
        "* In the previous example, we started from data stored in multidimensional NumPy arrays, also called **tensors**.\n",
        "* In general, all current machine-learning systems use tensors as their basic data structure.\n",
        "* You may be already familiar with matrices, which are rank-2 tensors: tensors are a **generalization of matrices to an arbitrary number of dimensions** (note that in the context of tensors, a dimension is often called an **axis**)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sunset-bathroom",
      "metadata": {
        "id": "sunset-bathroom"
      },
      "source": [
        "### Scalars (rank-0 tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "enclosed-maximum",
      "metadata": {
        "id": "enclosed-maximum",
        "outputId": "87e09942-2342-4eb1-8176-289b85a1350e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(12)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "x = np.array(12)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "raising-thread",
      "metadata": {
        "id": "raising-thread",
        "outputId": "31dc11dc-494f-4eb2-8fe7-4d69cfdafb20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pressed-toddler",
      "metadata": {
        "id": "pressed-toddler"
      },
      "source": [
        "* A tensor that contains only one number is called a **scalar** or **rank-0 tensor**.\n",
        "* In NumPy, a float32 or float64 number is a scalar tensor (or **scalar array**).\n",
        "* You can display the number of axes of a NumPy tensor via the ndim attribute.\n",
        "* The number of axes of a tensor is also called its rank."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dying-arizona",
      "metadata": {
        "id": "dying-arizona"
      },
      "source": [
        "### Vectors (rank-1 tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "marked-circus",
      "metadata": {
        "id": "marked-circus",
        "outputId": "74829106-bdef-49d2-9596-63951328fc76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([12,  3,  6, 14,  7])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.array([12, 3, 6, 14, 7])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tight-morrison",
      "metadata": {
        "id": "tight-morrison",
        "outputId": "091e23dd-065a-4d8e-e841-aded6bbd5d80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "classical-legislature",
      "metadata": {
        "id": "classical-legislature"
      },
      "source": [
        "* This vector has five entries and so is called a 5-dimensional vector.\n",
        "* Don’t confuse a 5D vector with a 5D tensor!.\n",
        "* **Dimensionality** can denote either the number of entries along a specific axis (as in the case of our 5D vector) or the number of axes in a tensor (such as a 5D tensor), which can be confusing at times."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pregnant-vintage",
      "metadata": {
        "id": "pregnant-vintage"
      },
      "source": [
        "### Matrices (rank-2 tensors)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "synthetic-nothing",
      "metadata": {
        "id": "synthetic-nothing"
      },
      "source": [
        "* An array of vectors is a matrix, or rank-2 tensor, or 2D tensor. A matrix has two axes (often referred to rows and columns)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "relevant-character",
      "metadata": {
        "id": "relevant-character",
        "outputId": "66775e41-41ac-46bb-daa1-12f4da43b865"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 5, 78,  2, 34,  0],\n",
              "       [ 6, 79,  3, 35,  1],\n",
              "       [ 7, 80,  4, 36,  2]])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.array([[5, 78, 2, 34, 0],\n",
        "            [6, 79, 3, 35, 1],\n",
        "            [7, 80, 4, 36, 2]])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "several-shopper",
      "metadata": {
        "id": "several-shopper",
        "outputId": "6bddac7d-3f6b-409c-91dd-2efbaffecdee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "listed-hughes",
      "metadata": {
        "id": "listed-hughes"
      },
      "source": [
        "### Rank-3 tensors and higher-rank tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "critical-superintendent",
      "metadata": {
        "id": "critical-superintendent"
      },
      "source": [
        "* If you pack such matrices in a new array, you obtain a rank-3 tensor (or 3D tensor), which you can visually interpret as a cube of numbers. Following is a NumPy rank-3 tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "theoretical-valve",
      "metadata": {
        "id": "theoretical-valve",
        "outputId": "711493b1-fcf4-4309-8e0a-d976e4d6c998"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.array([[[5, 78, 2, 34, 0],\n",
        "                [6, 79, 3, 35, 1],\n",
        "                [7, 80, 4, 36, 2]],\n",
        "                [[5, 78, 2, 34, 0],\n",
        "                [6, 79, 3, 35, 1],\n",
        "                [7, 80, 4, 36, 2]],\n",
        "                [[5, 78, 2, 34, 0],\n",
        "                [6, 79, 3, 35, 1],\n",
        "                [7, 80, 4, 36, 2]]])\n",
        "x.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "possible-search",
      "metadata": {
        "id": "possible-search"
      },
      "source": [
        "* In deep learning, you’ll generally manipulate tensors with ranks 0 to 4, although you may go up to 5 if you process video data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "english-cassette",
      "metadata": {
        "id": "english-cassette"
      },
      "source": [
        "### Key attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "waiting-exploration",
      "metadata": {
        "id": "waiting-exploration"
      },
      "source": [
        "A tensor is defined by three key attributes:\n",
        "* **Number of axes (rank)** — For instance, a rank-3 tensor has three axes, and a matrix has two axes. This is also called the tensor’s **ndim** in Python libraries such as NumPy or TensorFlow.\n",
        "* **Shape** — This is a tuple of integers that describes how many dimensions the tensor has along each axis. For instance, the previous matrix example has shape (3, 5), and the rank-3 tensor example has shape (3, 3, 5).\n",
        "* **Data type (usually called dtype in Python libraries)** — This is the type of the data contained in the tensor; for instance, a tensor’s type could be float16, float32, float64, uint8, and so on. In TensorFlow, you are also likely to come across string tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "classical-colony",
      "metadata": {
        "id": "classical-colony"
      },
      "source": [
        "To make this more concrete, let’s look back at the data we processed in the MNIST example. First, we load the MNIST dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "derived-reach",
      "metadata": {
        "id": "derived-reach"
      },
      "outputs": [],
      "source": [
        "(train_imagesORI, train_labelsORI), (test_imagesORI, test_labelsORI) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "operational-production",
      "metadata": {
        "id": "operational-production",
        "outputId": "417e8432-5116-4523-c7ee-ac0bac9d6203"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        }
      ],
      "source": [
        "print(train_imagesORI.ndim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dominican-grain",
      "metadata": {
        "id": "dominican-grain",
        "outputId": "6ceb5bd7-e739-4186-fd65-2290948beeeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "print(train_imagesORI.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mechanical-method",
      "metadata": {
        "id": "mechanical-method"
      },
      "source": [
        "#### So what we have here is a rank-3 tensor of 8-bit integers. More precisely, it’s an array of 60,000 matrices of 28 × 28 integers. Each such matrix is a grayscale image, with coefficients between 0 and 255."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "democratic-wisconsin",
      "metadata": {
        "id": "democratic-wisconsin"
      },
      "source": [
        "After reshape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "smaller-cooper",
      "metadata": {
        "id": "smaller-cooper",
        "outputId": "29c49ed3-095f-4d48-f8aa-aded952e1f92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "print(train_images.ndim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nearby-release",
      "metadata": {
        "id": "nearby-release",
        "outputId": "f21fc79e-58e7-4338-e3ad-afb4204f3c16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50000, 784)\n"
          ]
        }
      ],
      "source": [
        "print(train_images.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "alive-oasis",
      "metadata": {
        "id": "alive-oasis"
      },
      "source": [
        "# Manipulating tensors in NumPy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "destroyed-harbor",
      "metadata": {
        "id": "destroyed-harbor"
      },
      "source": [
        "### Tensor slicing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecological-exclusive",
      "metadata": {
        "id": "ecological-exclusive",
        "outputId": "0c74b555-4bfe-433d-a35e-8f223cdcc18f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(90, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "my_slice = train_imagesORI[10:100]\n",
        "print(my_slice.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "homeless-suite",
      "metadata": {
        "id": "homeless-suite",
        "outputId": "39c13b13-a5fc-451c-c50a-c722ff6d6e84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(90, 28, 28)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# It’s equivalent to this more detailed notation\n",
        "my_slice = train_imagesORI[10:100, :, :]\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "amber-payment",
      "metadata": {
        "id": "amber-payment",
        "outputId": "10514320-03c6-46a9-8bea-693b9808cc9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(90, 28, 28)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# It’s equivalent to this more detailed notation\n",
        "my_slice = train_imagesORI[10:100, 0:28, 0:28]\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "illegal-procedure",
      "metadata": {
        "id": "illegal-procedure",
        "outputId": "69d50020-40fb-4dc8-d024-4a43974e7ced"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 14, 14)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# What is the shape after the following slicing?\n",
        "my_slice = train_imagesORI[:, 7:-7, 7:-7]\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "boolean-manufacturer",
      "metadata": {
        "id": "boolean-manufacturer"
      },
      "source": [
        "### Data batches"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "collective-glossary",
      "metadata": {
        "id": "collective-glossary"
      },
      "source": [
        "* In all data tensors you’ll come across in deep learning will be the samples axis (sometimes called the samples dimension). In the MNIST example, samples are images of digits.\n",
        "*  In addition, deep-learning models don’t process an entire dataset at once; rather, they break the data into small batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "noticed-seeking",
      "metadata": {
        "id": "noticed-seeking"
      },
      "outputs": [],
      "source": [
        "# Concretely, here’s one batch of our MNIST digits, with batch size of 128:\n",
        "batch = train_images[:128] #first batch\n",
        "batch = train_images[128:256] #second batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stone-batch",
      "metadata": {
        "id": "stone-batch"
      },
      "outputs": [],
      "source": [
        "# And the nth batch:\n",
        "n = 3\n",
        "batch = train_images[128 * n:128 * (n + 1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "above-argentina",
      "metadata": {
        "id": "above-argentina"
      },
      "source": [
        "* When considering such a batch tensor, the first axis (axis 0) is called the batch axis or batch dimension. This is a term you’ll frequently encounter when using Keras and other deep-learning libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "environmental-glossary",
      "metadata": {
        "id": "environmental-glossary"
      },
      "source": [
        "### Real-world examples of data tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "right-cooper",
      "metadata": {
        "id": "right-cooper"
      },
      "source": [
        "The data you’ll manipulate will almost always fall into one of the following categories:\n",
        "* Vector data — rank-2 tensors of shape (samples, features)\n",
        "* Timeseries data or sequence data — rank-3 tensors of shape (samples, timesteps, features)\n",
        "* Images — rank-4 tensors of shape (samples, height, width, channels) or (samples, channels, height, width)\n",
        "* Video — rank-5 tensors of shape (samples, frames, height, width, channels) or (samples, frames, channels, height, width)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "devoted-right",
      "metadata": {
        "id": "devoted-right"
      },
      "source": [
        "Vector data: A dataset of text documents, where we represent each document by the counts of how\n",
        "many times each word appears in it (out of a dictionary of 20,000 common words).![vector_words.jpeg](images/vector_words.jpeg)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NQCbo2gN0vLE"
      },
      "id": "NQCbo2gN0vLE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "decreased-template",
      "metadata": {
        "id": "decreased-template"
      },
      "source": [
        "Time Series:\n",
        "![Timeseriesdata.png](https://raw.githubusercontent.com/hectormelo/Machine-Learning-Techniques/63d050457c26f88265bbd9c74323a3d5509dbdca/Lab_5/images/Timeseriesdata.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "norman-disease",
      "metadata": {
        "id": "norman-disease"
      },
      "source": [
        "Images:  ![images_repre.png](https://github.com/hectormelo/Machine-Learning-Techniques/blob/63d050457c26f88265bbd9c74323a3d5509dbdca/Lab_5/images/images_repre.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "immune-organizer",
      "metadata": {
        "id": "immune-organizer"
      },
      "source": [
        "# The gears of neural networks: tensor operations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "collective-basics",
      "metadata": {
        "id": "collective-basics"
      },
      "source": [
        "In our initial example, we were building our model by stacking Dense layers on top of each\n",
        "other. A Keras layer instance looks like this:\n",
        "\n",
        "**keras.layers.Dense(512, activation='relu')**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fantastic-protest",
      "metadata": {
        "id": "fantastic-protest"
      },
      "source": [
        "Specifically, the function is as follows (where W is a matrix and b is a vector, both attributes of the layer):"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "governing-arrangement",
      "metadata": {
        "id": "governing-arrangement"
      },
      "source": [
        "**output = relu(dot(W, input) + b)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "related-messaging",
      "metadata": {
        "id": "related-messaging"
      },
      "outputs": [],
      "source": [
        "# Element-wise operations\n",
        "def naive_relu(x):\n",
        "    assert len(x.shape) == 2 #x is a rank-2 NumPy tensor.\n",
        "    x = x.copy()  #Avoid overwriting the input tensor.\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] = max(x[i, j], 0)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "needed-annual",
      "metadata": {
        "id": "needed-annual"
      },
      "outputs": [],
      "source": [
        "def naive_add(x, y):\n",
        "    assert len(x.shape) == 2 #x and y are rank-2 NumPy tensors.\n",
        "    assert x.shape == y.shape\n",
        "    x = x.copy()  #Avoid overwriting the input tensor.\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[i, j]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "broke-spirit",
      "metadata": {
        "id": "broke-spirit"
      },
      "source": [
        "* The above functions are not optimized.\n",
        "* In practice, when dealing with NumPy arrays, these operations are available as well-optimized built-in NumPy functions, which themselves delegate the heavy lifting to a Basic Linear Algebra Subprograms (BLAS) implementation.\n",
        "* BLAS are low-level, highly parallel, efficient tensor-manipulation routines that are typically implemented in Fortran or C."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "equal-addition",
      "metadata": {
        "id": "equal-addition",
        "outputId": "5fae82f3-740b-426b-ae76-5ed0a584b251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Took: 1.18 s\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "x = np.random.random((20, 100))\n",
        "y = np.random.random((20, 100))\n",
        "t0 = time.time()\n",
        "for _ in range(1000):\n",
        "    z = naive_add(x, y)\n",
        "    z = naive_relu(z)\n",
        "print('Took: %.2f s' % (time.time() - t0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "broadband-watts",
      "metadata": {
        "id": "broadband-watts",
        "outputId": "b828547f-f5b2-4e7e-96c9-2496c21496b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Took: 0.00 s\n"
          ]
        }
      ],
      "source": [
        "#correct way\n",
        "t0 = time.time()\n",
        "for _ in range(1000):\n",
        "    z = x + y\n",
        "    z = np.maximum(z, 0.)\n",
        "print('Took: %.2f s' % (time.time() - t0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "choice-silver",
      "metadata": {
        "id": "choice-silver",
        "outputId": "ddf1388d-3a69-4b35-d4e1-d7ba60a2143b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20, 100)"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "included-communication",
      "metadata": {
        "id": "included-communication"
      },
      "source": [
        "## Tensor product\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "appreciated-eugene",
      "metadata": {
        "id": "appreciated-eugene",
        "outputId": "8af728f7-740f-4f94-ad66-0376c01fa485"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.17372663 0.0264011  0.2273696  0.30150137 0.70444335 0.61247062\n",
            " 0.89867467 0.64623836 0.22725018 0.39813829 0.74653353 0.31701991\n",
            " 0.20048027 0.33719906 0.0380097  0.22659746 0.71667711 0.56255948\n",
            " 0.79813784 0.10360243 0.16471718 0.13758667 0.33883356 0.58709061\n",
            " 0.16284479 0.23504205 0.98923819 0.39330715 0.40516208 0.51250127\n",
            " 0.36771752 0.00962664] [0.08161824 0.57176599 0.46581249 0.44146894 0.33856379 0.97520302\n",
            " 0.23747566 0.84230994 0.97596178 0.79037291 0.06668226 0.83755609\n",
            " 0.00175777 0.13319825 0.99291098 0.54470979 0.38439961 0.67782061\n",
            " 0.44887526 0.84201449 0.33771622 0.51852626 0.33730992 0.73629305\n",
            " 0.7633744  0.0863229  0.67815551 0.07075632 0.40493367 0.12704263\n",
            " 0.31920957 0.66582068] 5.892108395751747\n"
          ]
        }
      ],
      "source": [
        "x = np.random.random((32,))\n",
        "y = np.random.random((32,))\n",
        "z = np.dot(x, y)\n",
        "print(x,y,z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "contrary-finish",
      "metadata": {
        "id": "contrary-finish"
      },
      "outputs": [],
      "source": [
        "def naive_vector_dot(x, y):\n",
        "    assert len(x.shape) == 1\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[0] == y.shape[0]\n",
        "    z = 0.\n",
        "    for i in range(x.shape[0]):\n",
        "        z += x[i] * y[i]\n",
        "    return z"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "copyrighted-preserve",
      "metadata": {
        "id": "copyrighted-preserve"
      },
      "source": [
        "The dot product between a matrix x and a vector y, which returns a vector where the coefficients are the dot products between y and the rows of x.\n",
        "\n",
        "Of course, a dot product generalizes to tensors with an arbitrary number of axes. The most common applications may be the dot product between two matrices. You can take the dot product of two matrices x and y (dot(x, y)) if and only if x.shape[1] == y.shape[0]."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "periodic-thompson",
      "metadata": {
        "id": "periodic-thompson"
      },
      "source": [
        "![dotproduct.jpg](https://github.com/hectormelo/Machine-Learning-Techniques/blob/63d050457c26f88265bbd9c74323a3d5509dbdca/Lab_5/images/dotproduct.jpg?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "viral-opportunity",
      "metadata": {
        "id": "viral-opportunity"
      },
      "source": [
        "# Geometric interpretation of tensor operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "governmental-incentive",
      "metadata": {
        "id": "governmental-incentive"
      },
      "outputs": [],
      "source": [
        "A = [0.5, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "final-subcommittee",
      "metadata": {
        "id": "final-subcommittee"
      },
      "source": [
        "![Vectors_2.png](https://github.com/hectormelo/Machine-Learning-Techniques/blob/63d050457c26f88265bbd9c74323a3d5509dbdca/Lab_5/images/Vectors_2.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rotary-findings",
      "metadata": {
        "id": "rotary-findings"
      },
      "outputs": [],
      "source": [
        "B = [1, 0.25]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "occasional-growth",
      "metadata": {
        "id": "occasional-growth"
      },
      "source": [
        "![Vectors_3.png](https://raw.githubusercontent.com/hectormelo/Machine-Learning-Techniques/63d050457c26f88265bbd9c74323a3d5509dbdca/Lab_5/images/Vectors_3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "appreciated-guyana",
      "metadata": {
        "id": "appreciated-guyana"
      },
      "source": [
        "### Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "passive-router",
      "metadata": {
        "id": "passive-router"
      },
      "source": [
        "![Translation.png](https://raw.githubusercontent.com/hectormelo/Machine-Learning-Techniques/63d050457c26f88265bbd9c74323a3d5509dbdca/Lab_5/images/Translation.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "changed-trial",
      "metadata": {
        "id": "changed-trial"
      },
      "source": [
        "### Rotation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "junior-bandwidth",
      "metadata": {
        "id": "junior-bandwidth"
      },
      "source": [
        "A rotation of a 2D vector by an angle theta (see figure) can be achieved via a dot product with a 2 × 2 matrix R = [[cos(theta), sin(theta)], [-sin(theta), cos(theta)]]."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "continued-spirituality",
      "metadata": {
        "id": "continued-spirituality"
      },
      "source": [
        "![rotation.png](https://raw.githubusercontent.com/hectormelo/Machine-Learning-Techniques/63d050457c26f88265bbd9c74323a3d5509dbdca/Lab_5/images/rotation.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "banner-advancement",
      "metadata": {
        "id": "banner-advancement"
      },
      "source": [
        "### Scaling\n",
        "A vertical and horizontal scaling of the image (see figure) can be achieved via a dot product with a 2 x 2 matrix S = (note that such a matrix is called a 'diagonal matrix', because it only has non-zero coefficients in its “diagonal”, going from the top left to the bottom right)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "heated-rachel",
      "metadata": {
        "id": "heated-rachel"
      },
      "source": [
        "![scaling.png](https://raw.githubusercontent.com/hectormelo/Machine-Learning-Techniques/63d050457c26f88265bbd9c74323a3d5509dbdca/Lab_5/images/scaling.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "norwegian-infrared",
      "metadata": {
        "id": "norwegian-infrared"
      },
      "source": [
        "### Affine transform"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "first-encyclopedia",
      "metadata": {
        "id": "first-encyclopedia"
      },
      "source": [
        "An affine transform (see figure TODO) is the combination of a linear transform (achieved via a dot product some matrix) and a translation (achieved via a vector addition)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cooperative-morning",
      "metadata": {
        "id": "cooperative-morning"
      },
      "source": [
        "![affine.png](https://raw.githubusercontent.com/hectormelo/Machine-Learning-Techniques/63d050457c26f88265bbd9c74323a3d5509dbdca/Lab_5/images/affine.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "weird-evanescence",
      "metadata": {
        "id": "weird-evanescence"
      },
      "source": [
        "As you have probably recognized, that’s exactly the y = W • x + b computation implemented by the Dense layer!, logistic regression and so on.  A Dense layer without an activation function is an affine layer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vulnerable-harvey",
      "metadata": {
        "id": "vulnerable-harvey"
      },
      "source": [
        "### Dense layer with relu activation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "facial-tokyo",
      "metadata": {
        "id": "facial-tokyo"
      },
      "source": [
        "![relu.png](https://raw.githubusercontent.com/hectormelo/Machine-Learning-Techniques/63d050457c26f88265bbd9c74323a3d5509dbdca/Lab_5/images/relu.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "satisfactory-distribution",
      "metadata": {
        "id": "satisfactory-distribution"
      },
      "source": [
        " ## The engine of neural networks: gradient-based optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "grave-attendance",
      "metadata": {
        "id": "grave-attendance"
      },
      "source": [
        "output = relu(dot(W, input) + b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "automotive-breakfast",
      "metadata": {
        "id": "automotive-breakfast"
      },
      "source": [
        "How to find W and B?, training loop.\n",
        "1. Draw a batch of training samples x and corresponding targets y_true.\n",
        "2. Run the model on x (a step called the forward pass) to obtain predictions y_pred.\n",
        "3. Compute the loss of the model on the batch, a measure of the mismatch between y_pred and y_true.\n",
        "4. Update all weights of the model in a way that slightly reduces the loss on this batch."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fleet-marks",
      "metadata": {
        "id": "fleet-marks"
      },
      "source": [
        "### Stochastic gradient descent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "detected-tracker",
      "metadata": {
        "id": "detected-tracker"
      },
      "source": [
        "Given a differentiable function, it’s theoretically possible to find its minimum analytically: it’s known that a function’s minimum is a point where the derivative is 0, so all you have to do is\n",
        "find all the points where the derivative goes to 0 and check for which of these points the function has the lowest value."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caroline-divorce",
      "metadata": {
        "id": "caroline-divorce"
      },
      "source": [
        "### grad(f(W), W) = 0 for W.\n",
        "This is a polynomial equation of N variables, where N is the number\n",
        "of coefficients in the model. Although it would be possible to solve such an equation for N = 2 or\n",
        "N = 3, doing so is intractable for real neural networks, where the number of parameters is never\n",
        "less than a few thousand and can often be several tens of millions.\n",
        "\n",
        "Instead, you can use the four-step algorithm outlined: modify the\n",
        "parameters little by little based on the current loss value on a random batch of data. Because\n",
        "you’re dealing with a differentiable function, you can compute its gradient, which gives you an\n",
        "efficient way to implement step 4. If you update the weights in the opposite direction from the\n",
        "gradient, the loss will be a little less every time:\n",
        "\n",
        "1. Draw a batch of training samples x and corresponding targets y_true.\n",
        "2. Run the model on x to obtain predictions y_pred (this is called the forward pass).\n",
        "3. Compute the loss of the model on the batch, a measure of the mismatch between y_pred and y_true.\n",
        "4. Compute the gradient of the loss with regard to the model’s parameters (this is called the backward pass).\n",
        "5. Move the parameters a little in the opposite direction from the gradient — for example W -= learning_rate * gradient — thus reducing the loss on the batch a bit. The learning rate (learning_rate here) would be a scalar factor modulating the “speed” of the gradient descent process."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "meaningful-clarity",
      "metadata": {
        "id": "meaningful-clarity"
      },
      "source": [
        "What we just described is called **mini-batch stochastic gradient descent (mini-batch SGD)**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cathedral-mount",
      "metadata": {
        "id": "cathedral-mount"
      },
      "source": [
        "![SGD.png](https://raw.githubusercontent.com/hectormelo/Machine-Learning-Techniques/63d050457c26f88265bbd9c74323a3d5509dbdca/Lab_5/images/SGD.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "graphic-diamond",
      "metadata": {
        "id": "graphic-diamond"
      },
      "source": [
        "As you can see, intuitively it’s important to pick a reasonable value for the **learning_rate factor**. If it’s too small, the descent down the curve will take many iterations, and it could get\n",
        "stuck in a **local minimum**. If learning_rate is too large, your updates may end up taking you to completely random locations on the curve."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "million-disco",
      "metadata": {
        "id": "million-disco"
      },
      "source": [
        "![local_minimun.png](https://github.com/hectormelo/Machine-Learning-Techniques/blob/63d050457c26f88265bbd9c74323a3d5509dbdca/Lab_5/images/local_minimun.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "certified-provider",
      "metadata": {
        "id": "certified-provider"
      },
      "source": [
        "![SDG-3d.png](https://github.com/hectormelo/Machine-Learning-Techniques/blob/63d050457c26f88265bbd9c74323a3d5509dbdca/Lab_5/images/SDG-3d.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "affected-bidder",
      "metadata": {
        "id": "affected-bidder"
      },
      "source": [
        "Additionally, there exist multiple variants of SGD that differ by taking into account previous weight updates. Such variants are known as **optimization methods or optimizers**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceramic-classic",
      "metadata": {
        "id": "ceramic-classic"
      },
      "source": [
        "## Chaining derivatives: the Backpropagation algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "threaded-region",
      "metadata": {
        "id": "threaded-region"
      },
      "source": [
        "In our two-layer network example, how can we get the gradient of the\n",
        "loss with regard to the weights?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sensitive-essay",
      "metadata": {
        "id": "sensitive-essay"
      },
      "source": [
        "```python\n",
        "loss_value = loss(y_true, softmax(dot(W2, relu(dot(W1, inputs) + b1)) + b2))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "amber-depth",
      "metadata": {
        "id": "amber-depth"
      },
      "source": [
        "##![TwoLayerNNComputingGraph.png](attachment:33d8cd06-05a0-44d1-af0f-bb24dfe7dfa4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "peripheral-change",
      "metadata": {
        "id": "peripheral-change"
      },
      "source": [
        "## An easy example of Backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "annoying-birth",
      "metadata": {
        "id": "annoying-birth"
      },
      "source": [
        "We’ll take two scalar variables w, b, a scalar input x, and apply some operations to them to combine into an output y. we’ll apply an absolute value error:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "moral-truth",
      "metadata": {
        "id": "moral-truth"
      },
      "source": [
        "<code>\n",
        "loss_val = abs(y_true - y)\n",
        "</code>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "maritime-class",
      "metadata": {
        "id": "maritime-class"
      },
      "source": [
        "![BackpropaExample.png](https://github.com/hectormelo/Machine-Learning-Techniques/blob/63d050457c26f88265bbd9c74323a3d5509dbdca/Lab_5/images/BackpropaExample.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "national-thing",
      "metadata": {
        "id": "national-thing"
      },
      "source": [
        "### Now let's **reverse** the graph: for each edge in the graph going from a to b, we will create an opposite edge from b to a, and ask “how much does b vary when a vary”?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "green-interstate",
      "metadata": {
        "id": "green-interstate"
      },
      "source": [
        "![BackpropaExample2.png](https://github.com/hectormelo/Machine-Learning-Techniques/blob/63d050457c26f88265bbd9c74323a3d5509dbdca/Lab_5/images/BackpropaExample2.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "covered-discount",
      "metadata": {
        "id": "covered-discount"
      },
      "source": [
        "We have:\n",
        "* <code>grad(loss_val, x2) = 1</code>, because as x2 varies by an amount epsilon, <code>loss_val = abs(4 - x2)</code> varies by the same amount.\n",
        "* <code>grad(x2, x1) = 1</code>, because as x1 varies by an amount epsilon, <code>x2 = x1 + b = x1 + 1</code> varies by the same amount.\n",
        "* <code>grad(x2, b) = 1</code>, because as b varies by an amount epsilon, <code>x2 = x1 + b = 6 + b</code> varies by the same amount.\n",
        "* <code>grad(x1, w) = 2</code>, because as w varies by an amount epsilon, <code>x1 = x * w = 2 * w</code> varies by 2 * epsilon."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "organized-certificate",
      "metadata": {
        "id": "organized-certificate"
      },
      "source": [
        "What the chain rule says about this backward graph is that **you can obtain the derivative of a\n",
        "node with respect to another node by multiplying the derivatives for each edge along the path\n",
        "linking the two nodes**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "biological-worcester",
      "metadata": {
        "id": "biological-worcester"
      },
      "source": [
        "### grad(loss_val, w)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "representative-hurricane",
      "metadata": {
        "id": "representative-hurricane"
      },
      "source": [
        "![BackpropaExample3.png](https://github.com/hectormelo/Machine-Learning-Techniques/blob/63d050457c26f88265bbd9c74323a3d5509dbdca/Lab_5/images/BackpropaExample3.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "democratic-booth",
      "metadata": {
        "id": "democratic-booth"
      },
      "source": [
        "* grad(loss_val, w) = 1 * 1 * 2 = 2\n",
        "* grad(loss_val, b) = 1 * 1 = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "weighted-portfolio",
      "metadata": {
        "id": "weighted-portfolio"
      },
      "source": [
        "# THE GRADIENT TAPE IN TENSORFLOW"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lonely-raise",
      "metadata": {
        "id": "lonely-raise"
      },
      "source": [
        "The API through which you can leverage TensorFlow’s powerful automatic differentiation\n",
        "capabilities is the GradientTape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "australian-hygiene",
      "metadata": {
        "id": "australian-hygiene",
        "outputId": "19294ee0-8b41-427a-91ed-24ca6cf91c6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(2.0, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "x = tf.Variable(0.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y = 2 * x   + 3\n",
        "\n",
        "grad_of_y_wrt_x = tape.gradient(y, x)\n",
        "print(grad_of_y_wrt_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "phantom-income",
      "metadata": {
        "id": "phantom-income"
      },
      "outputs": [],
      "source": [
        "# tape == computation graph\n",
        "# tf.Variable is a specific kind of tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fiscal-danger",
      "metadata": {
        "id": "fiscal-danger"
      },
      "source": [
        "# (OPTIONAL) Reimplementing our first example using all that we learn so far"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "upper-washer",
      "metadata": {
        "id": "upper-washer"
      },
      "source": [
        "#### First implement a NaiveDense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "integrated-ultimate",
      "metadata": {
        "id": "integrated-ultimate"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class NaiveDense:\n",
        "    def __init__(self, input_size, output_size, activation):\n",
        "        self.activation = activation\n",
        "\n",
        "        # Create a matrix W of shape “(input_size, output_size)“,\n",
        "        # initialized with randomvalues.\n",
        "        w_shape = (input_size, output_size)\n",
        "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
        "        self.W = tf.Variable(w_initial_value)\n",
        "\n",
        "        # Create a vector b of shape (output_size,), initialized with zeros.\n",
        "        b_shape = (output_size,)\n",
        "        b_initial_value = tf.zeros(b_shape)\n",
        "        self.b = tf.Variable(b_initial_value)\n",
        "\n",
        "    def __call__(self, inputs): #Apply the forward pass.\n",
        "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
        "\n",
        "    # Convenience method for retrieving the layer’s weights.\n",
        "    @property\n",
        "    def weights(self):\n",
        "        return [self.W, self.b]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "running-knight",
      "metadata": {
        "id": "running-knight"
      },
      "source": [
        "#### Second implement the computation of a sequence of layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hidden-helena",
      "metadata": {
        "id": "hidden-helena"
      },
      "outputs": [],
      "source": [
        "class NaiveSequential:\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "        weights = []\n",
        "        for layer in self.layers:\n",
        "            weights += layer.weights\n",
        "        return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "substantial-strategy",
      "metadata": {
        "id": "substantial-strategy",
        "outputId": "ff7f6e6c-656d-4d98-9d08-2e7c6a70d6cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Now we can initialice our NN architecture\n",
        "model = NaiveSequential([\n",
        "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
        "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
        "    ])\n",
        "len(model.weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "forbidden-planner",
      "metadata": {
        "id": "forbidden-planner"
      },
      "source": [
        "#### Build the batch generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "central-colony",
      "metadata": {
        "id": "central-colony"
      },
      "outputs": [],
      "source": [
        "class BatchGenerator:\n",
        "    def __init__(self, images, labels, batch_size=128):\n",
        "        self.index = 0\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def next(self):\n",
        "        images = self.images[self.index : self.index + self.batch_size]\n",
        "        labels = self.labels[self.index : self.index + self.batch_size]\n",
        "        self.index += self.batch_size\n",
        "        return images, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "automotive-british",
      "metadata": {
        "id": "automotive-british"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "certified-clinton",
      "metadata": {
        "id": "certified-clinton"
      },
      "outputs": [],
      "source": [
        "def one_training_step(model, images_batch, labels_batch):\n",
        "    # Run the “forward pass”\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images_batch)\n",
        "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(labels_batch, predictions)\n",
        "        average_loss = tf.reduce_mean(per_sample_losses)\n",
        "\n",
        "    # Compute the gradient of the loss with regard to the weights. The output gradients\n",
        "    # is a list where each entry corresponds to a weight from the model.weights list.\n",
        "    gradients = tape.gradient(average_loss, model.weights)\n",
        "\n",
        "    # Update the weights using the gradients (we will define this function below)\n",
        "    update_weights(gradients, model.weights)\n",
        "    return average_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "proved-israeli",
      "metadata": {
        "id": "proved-israeli"
      },
      "source": [
        "#### What is missing here?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "exclusive-plymouth",
      "metadata": {
        "id": "exclusive-plymouth"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "def update_weights(gradients, weights):\n",
        "    for g, w in zip(gradients, model.weights):\n",
        "        w.assign_sub(g * learning_rate) #\n",
        "        #assign_sub is the equivalent of -= for TensorFlow variables. w2 = w1 - w1*gradiente"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "surrounded-priority",
      "metadata": {
        "id": "surrounded-priority"
      },
      "source": [
        "In practice, you will almost never implement a weight update step like this by hand. Instead, you would use an **Optimizer instance from Keras**. Like this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "auburn-programmer",
      "metadata": {
        "id": "auburn-programmer"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import optimizers\n",
        "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
        "def update_weights(gradients, weights):\n",
        "    optimizer.apply_gradients(zip(gradients, weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hybrid-command",
      "metadata": {
        "id": "hybrid-command"
      },
      "source": [
        "### Putting it all together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "demanding-partner",
      "metadata": {
        "id": "demanding-partner"
      },
      "outputs": [],
      "source": [
        "def fit(model, images, labels, epochs, batch_size=128):\n",
        "    for epoch_counter in range(epochs):\n",
        "        print('Epoch %d' % epoch_counter)\n",
        "        batch_generator = BatchGenerator(images, labels)\n",
        "        for batch_counter in range(len(images) // batch_size):\n",
        "            images_batch, labels_batch = batch_generator.next()\n",
        "            loss = one_training_step(model, images_batch, labels_batch)\n",
        "            if batch_counter % 100 == 0:\n",
        "                print('loss at batch %d: %.2f' % (batch_counter, loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "continent-dayton",
      "metadata": {
        "id": "continent-dayton"
      },
      "source": [
        "### Let's probe our implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "confident-wales",
      "metadata": {
        "id": "confident-wales"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "patient-longitude",
      "metadata": {
        "id": "patient-longitude",
        "outputId": "9f04e86d-4398-4521-9eca-05c13a6c923b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "loss at batch 0: 0.61\n",
            "loss at batch 100: 0.67\n",
            "loss at batch 200: 0.57\n",
            "loss at batch 300: 0.63\n",
            "loss at batch 400: 0.70\n",
            "Epoch 1\n",
            "loss at batch 0: 0.58\n",
            "loss at batch 100: 0.63\n",
            "loss at batch 200: 0.54\n",
            "loss at batch 300: 0.60\n",
            "loss at batch 400: 0.68\n",
            "Epoch 2\n",
            "loss at batch 0: 0.56\n",
            "loss at batch 100: 0.60\n",
            "loss at batch 200: 0.51\n",
            "loss at batch 300: 0.57\n",
            "loss at batch 400: 0.65\n",
            "Epoch 3\n",
            "loss at batch 0: 0.53\n",
            "loss at batch 100: 0.57\n",
            "loss at batch 200: 0.49\n",
            "loss at batch 300: 0.55\n",
            "loss at batch 400: 0.63\n",
            "Epoch 4\n",
            "loss at batch 0: 0.52\n",
            "loss at batch 100: 0.55\n",
            "loss at batch 200: 0.47\n",
            "loss at batch 300: 0.53\n",
            "loss at batch 400: 0.62\n",
            "Epoch 5\n",
            "loss at batch 0: 0.50\n",
            "loss at batch 100: 0.53\n",
            "loss at batch 200: 0.45\n",
            "loss at batch 300: 0.51\n",
            "loss at batch 400: 0.60\n",
            "Epoch 6\n",
            "loss at batch 0: 0.49\n",
            "loss at batch 100: 0.51\n",
            "loss at batch 200: 0.43\n",
            "loss at batch 300: 0.50\n",
            "loss at batch 400: 0.59\n",
            "Epoch 7\n",
            "loss at batch 0: 0.47\n",
            "loss at batch 100: 0.49\n",
            "loss at batch 200: 0.42\n",
            "loss at batch 300: 0.48\n",
            "loss at batch 400: 0.58\n",
            "Epoch 8\n",
            "loss at batch 0: 0.46\n",
            "loss at batch 100: 0.48\n",
            "loss at batch 200: 0.41\n",
            "loss at batch 300: 0.47\n",
            "loss at batch 400: 0.57\n",
            "Epoch 9\n",
            "loss at batch 0: 0.45\n",
            "loss at batch 100: 0.46\n",
            "loss at batch 200: 0.39\n",
            "loss at batch 300: 0.46\n",
            "loss at batch 400: 0.56\n"
          ]
        }
      ],
      "source": [
        "## let's fit\n",
        "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "important-budget",
      "metadata": {
        "id": "important-budget"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stunning-appearance",
      "metadata": {
        "id": "stunning-appearance",
        "outputId": "c42d1ec8-5f50-4a65-8a78-90ccb51ca6f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 0.87\n"
          ]
        }
      ],
      "source": [
        "predictions = model(test_images)\n",
        "predictions = predictions.numpy()# Tensorflow tensor to numpy tensor\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "matches = predicted_labels == test_labels\n",
        "print('accuracy: %.2f' % matches.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7cb7648-c203-4890-9276-32d42dfefb83",
      "metadata": {
        "id": "d7cb7648-c203-4890-9276-32d42dfefb83"
      },
      "source": [
        "# TALLER SEMANA 9"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddd43f43-d83d-4178-9337-f413f36e12b3",
      "metadata": {
        "id": "ddd43f43-d83d-4178-9337-f413f36e12b3"
      },
      "source": [
        "Seleccione dos (2) datasets de *\"clasificación\"* de los previamente usados en los laboratorios.\n",
        "\n",
        "**Para cada uno de los datasets construya una red neuronal (solo capas densas) en keras que solucione el problema.**\n",
        "- Experimente cambiando la arquitectura de la red neuronal (# capas ocultas, y # capas de neuronas) -mínimo 3 arquitecturas-. Documente para cada arquitectura los resultados en Training, Validación y Test.\n",
        "- Para cada arquitectura planteada haga un summary y entienda el conteo total de parámetros de cada capa.\n",
        "- Para cada arquitectura evaluada encuentre el número apropiado de epocas de entrenamiento.\n",
        "- Compare los resultados con los obtenidos utilizando otros métodos de ML (SVM, Random Forest, etc).\n",
        "\n",
        "**Sobre el formato de entrega:**\n",
        "- Cree un (1) nuevo notebook para resolver la tarea. No haga su tarea sobre este notebook!!.\n",
        "- Use la nomenclatura de nombres usanda en talleres pasados para nombrar el archivo ipynb.\n",
        "- En el notebook solo deje especificado la arquitectura que mejor resolvio cada uno de los dos problema. Las otras arquitecturas de red probadas solo debe documentarlas y hacer la comparación en terminos de resultados. La documentación debe ser incluida en el mismo notebook. Si usa imagenes no olvide incluirlas en la entrega.  \n",
        "\n",
        "**Apreciaciones Finales:**\n",
        "-  Defina un dataset de validación de mínimo el 10% en caso de que no este especificado. Recuerde que debe ser una selección aleatoria.\n",
        "-  Sea organizado en la presentación de notebooks y en la documentación de la experimentación/comparación de resultados."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}